# åŠŸèƒ½ï¼šåˆ†æå±±å¯¨å¸ä¸BTCçš„çš®å°”é€Šç›¸å…³ç³»æ•°ï¼Œè¯†åˆ«å­˜åœ¨æ—¶é—´å·®å¥—åˆ©ç©ºé—´çš„å¼‚å¸¸å¸ç§
# åŸç†ï¼šé€šè¿‡è®¡ç®—ä¸åŒæ—¶é—´å‘¨æœŸå’Œå»¶è¿Ÿä¸‹çš„ç›¸å…³ç³»æ•°ï¼Œæ‰¾å‡ºçŸ­æœŸä½ç›¸å…³ä½†é•¿æœŸé«˜ç›¸å…³çš„å¸ç§

import ccxt
import time
import logging
from logging.handlers import RotatingFileHandler
import numpy as np
import pandas as pd
from retry import retry
from utils.lark_bot import sender
from utils.config import lark_bot_id


def setup_logging(log_file="hyperliquid.log", level=logging.DEBUG):
    """
    é…ç½®æ—¥å¿—ç³»ç»Ÿï¼Œæ”¯æŒæ§åˆ¶å°å’Œæ–‡ä»¶è¾“å‡º
    
    Args:
        log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
        level: æ—¥å¿—çº§åˆ«
    
    Returns:
        é…ç½®å¥½çš„ logger å®ä¾‹
    """
    log = logging.getLogger(__name__)
    
    # é¿å…é‡å¤æ·»åŠ  handlers
    if log.handlers:
        return log
    
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    
    # æ–‡ä»¶å¤„ç†å™¨ï¼ˆ10MBè½®è½¬ï¼Œä¿ç•™5ä¸ªå¤‡ä»½ï¼‰
    file_handler = RotatingFileHandler(
        log_file, maxBytes=10*1024*1024, backupCount=5, encoding='utf-8'
    )
    file_handler.setFormatter(formatter)
    
    # é…ç½® logger
    log.setLevel(level)
    log.propagate = False  # é˜»æ­¢æ—¥å¿—ä¼ æ’­åˆ°æ ¹ loggerï¼Œé¿å…é‡å¤æ‰“å°
    log.addHandler(console_handler)
    log.addHandler(file_handler)
    
    return log


logger = setup_logging()


class DelayCorrelationAnalyzer:
    """
    å±±å¯¨å¸ä¸BTCç›¸å…³ç³»æ•°åˆ†æå™¨

    è¯†åˆ«çŸ­æœŸä½ç›¸å…³ä½†é•¿æœŸé«˜ç›¸å…³çš„å¼‚å¸¸å¸ç§ï¼Œè¿™ç±»å¸ç§å­˜åœ¨æ—¶é—´å·®å¥—åˆ©æœºä¼šã€‚
    """
    # ç›¸å…³ç³»æ•°è®¡ç®—æ‰€éœ€çš„æœ€å°æ•°æ®ç‚¹æ•°
    MIN_POINTS_FOR_CORR_CALC = 10
    # æ•°æ®åˆ†ææ‰€éœ€çš„æœ€å°æ•°æ®ç‚¹æ•°
    MIN_DATA_POINTS_FOR_ANALYSIS = 50

    # å¼‚å¸¸æ¨¡å¼æ£€æµ‹é˜ˆå€¼
    # é•¿æœŸç›¸å…³ç³»æ•°é˜ˆå€¼ï¼Œç›®æ ‡éœ€è¦åœ¨ä¸‹é¢è¿™ä¸¤ä¸ªå€¼çš„èŒƒå›´å†…ï¼Œå¦åˆ™ä¸å‘Šè­¦
    LONG_TERM_CORR_THRESHOLD = 0.6
    # çŸ­æœŸç›¸å…³ç³»æ•°é˜ˆå€¼ï¼Œ
    SHORT_TERM_CORR_THRESHOLD = 0.4  

    # ç›¸å…³ç³»æ•°å·®å€¼é˜ˆå€¼ï¼Œå¦‚æœå°äºè¿™ä¸ªå€¼å°±ä¸å‘Šè­¦
    CORR_DIFF_THRESHOLD = 0.38

    # ========== æ–°å¢ï¼šå¼‚å¸¸å€¼å¤„ç†é…ç½® ==========
    # Winsorization åˆ†ä½æ•°é…ç½®
    WINSORIZE_LOWER_PERCENTILE = 0.1   # ä¸‹åˆ†ä½æ•°ï¼ˆ0.1%ï¼‰
    WINSORIZE_UPPER_PERCENTILE = 99.9  # ä¸Šåˆ†ä½æ•°ï¼ˆ99.9%ï¼‰
    # æ˜¯å¦å¯ç”¨å¼‚å¸¸å€¼å¤„ç†ï¼ˆå¯é…ç½®å¼€å…³ï¼‰
    ENABLE_OUTLIER_TREATMENT = True

    # ========== æ–°å¢ï¼šBeta ç³»æ•°é…ç½® ==========
    # æ˜¯å¦è®¡ç®— Beta ç³»æ•°ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    ENABLE_BETA_CALCULATION = True
    # Beta ç³»æ•°çš„æœ€å°æ•°æ®ç‚¹è¦æ±‚ï¼ˆä¸ç›¸å…³ç³»æ•°ç›¸åŒï¼‰
    MIN_POINTS_FOR_BETA_CALC = 10
    # å¹³å‡Betaç³»æ•°é˜ˆå€¼ï¼Œå¦‚æœå°äºè¿™ä¸ªå€¼å°±ä¸å‘Šè­¦
    AVG_BETA_THRESHOLD = 1
    
    # ========== æ–°å¢ï¼šZ-score é…ç½® ==========
    # æ˜¯å¦å¯ç”¨ Z-score æ£€æŸ¥ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    ENABLE_ZSCORE_CHECK = True
    # Z-score é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼æ‰è®¤ä¸ºæ˜¯æ˜¾è‘—çš„å¥—åˆ©æœºä¼š
    ZSCORE_THRESHOLD = 2.0  # æ ‡å‡†å·®å€æ•°
    # Z-score è®¡ç®—çš„æ»šåŠ¨çª—å£å¤§å°
    ZSCORE_WINDOW = 20  # å»ºè®®å€¼ï¼š20-30ï¼Œæ ¹æ®æ•°æ®é¢‘ç‡è°ƒæ•´
    
    def __init__(self, exchange_name="kucoin", timeout=30000, default_combinations=None):
        """
        åˆå§‹åŒ–åˆ†æå™¨
        
        Args:
            exchange_name: äº¤æ˜“æ‰€åç§°ï¼Œæ”¯æŒccxtåº“æ”¯æŒçš„æ‰€æœ‰äº¤æ˜“æ‰€
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
            default_combinations: Kçº¿ç»„åˆåˆ—è¡¨ï¼Œå¦‚ [("5m", "7d"), ("1m", "1d")]
        """
        self.exchange_name = exchange_name
        self.exchange = getattr(ccxt, exchange_name)({
            "timeout": timeout,
            "enableRateLimit": True,
            "rateLimit": 1500
        })
        # åªä¿ç•™ä¸¤ä¸ªç»„åˆï¼š5åˆ†é’ŸKçº¿7å¤©ï¼Œ1åˆ†é’ŸKçº¿1å¤©
        self.combinations = default_combinations or [("5m", "7d"), ("1m", "1d")]
        self.btc_symbol = "BTC/USDC:USDC"
        self.btc_df_cache = {}
        self.alt_df_cache = {}  # å±±å¯¨å¸æ•°æ®ç¼“å­˜
        
        # æ£€æŸ¥ lark_bot_id æ˜¯å¦æœ‰æ•ˆ
        if not lark_bot_id:
            logger.warning("ç¯å¢ƒå˜é‡ LARKBOT_ID æœªè®¾ç½®ï¼Œé£ä¹¦é€šçŸ¥åŠŸèƒ½å°†ä¸å¯ç”¨")
            self.lark_hook = None
        else:
            self.lark_hook = f'https://open.feishu.cn/open-apis/bot/v2/hook/{lark_bot_id}'

    @staticmethod
    def _timeframe_to_minutes(timeframe: str) -> int:
        """
        å°† timeframe å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ†é’Ÿæ•°
        
        æ”¯æŒçš„æ ¼å¼ï¼š
        - åˆ†é’Ÿï¼š1m, 5m, 15m, 30m
        - å°æ—¶ï¼š1h, 4h, 12h
        - å¤©ï¼š1d, 3d
        - å‘¨ï¼š1w
        
        Args:
            timeframe: Kçº¿æ—¶é—´å‘¨æœŸå­—ç¬¦ä¸²
        
        Returns:
            å¯¹åº”çš„åˆ†é’Ÿæ•°
        
        Raises:
            ValueError: ä¸æ”¯æŒçš„ timeframe æ ¼å¼
        """
        unit_multipliers = {
            'm': 1,
            'h': 60,
            'd': 24 * 60,
            'w': 7 * 24 * 60,
        }
        
        unit = timeframe[-1].lower()
        if unit not in unit_multipliers:
            raise ValueError(f"ä¸æ”¯æŒçš„ timeframe æ ¼å¼: {timeframe}ï¼Œæ”¯æŒçš„å•ä½: m, h, d, w")
        
        try:
            value = int(timeframe[:-1])
        except ValueError:
            raise ValueError(f"æ— æ•ˆçš„ timeframe æ ¼å¼: {timeframe}ï¼Œæ•°å€¼éƒ¨åˆ†å¿…é¡»æ˜¯æ•´æ•°")
        
        return value * unit_multipliers[unit]
    
    @staticmethod
    def _period_to_bars(period: str, timeframe: str) -> int:
        """å°†æ—¶é—´å‘¨æœŸè½¬æ¢ä¸ºKçº¿æ€»æ¡æ•°"""
        days = int(period.rstrip('d'))
        timeframe_minutes = DelayCorrelationAnalyzer._timeframe_to_minutes(timeframe)
        bars_per_day = int(24 * 60 / timeframe_minutes)
        return days * bars_per_day
    
    def _safe_download(self, symbol: str, period: str, timeframe: str, coin: str = None) -> pd.DataFrame | None:
        """
        å®‰å…¨ä¸‹è½½æ•°æ®ï¼Œå¤±è´¥æ—¶è¿”å›Noneå¹¶è®°å½•æ—¥å¿—
        
        Args:
            symbol: äº¤æ˜“å¯¹åç§°
            period: æ•°æ®å‘¨æœŸ
            timeframe: Kçº¿æ—¶é—´å‘¨æœŸ
            coin: ç”¨äºæ—¥å¿—çš„å¸ç§åç§°ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æˆåŠŸè¿”å›DataFrameï¼Œå¤±è´¥è¿”å›None
        """
        display_name = coin or symbol
        return self._safe_execute(
            self.download_ccxt_data,
            symbol, period=period, timeframe=timeframe,
            error_msg=f"ä¸‹è½½ {display_name} çš„ {timeframe}/{period} æ•°æ®å¤±è´¥"
        )
    
    @retry(tries=10, delay=5, backoff=2, logger=logger)
    def download_ccxt_data(self, symbol: str, period: str, timeframe: str) -> pd.DataFrame:
        """
        ä»äº¤æ˜“æ‰€ä¸‹è½½OHLCVå†å²æ•°æ®
        
        Args:
            symbol: äº¤æ˜“å¯¹åç§°ï¼Œå¦‚ "BTC/USDC"
            period: æ•°æ®å‘¨æœŸï¼Œå¦‚ "30d"
            timeframe: Kçº¿æ—¶é—´å‘¨æœŸï¼Œå¦‚ "5m"
        
        Returns:
            åŒ…å« Open/High/Low/Close/Volume/return/volume_usd åˆ—çš„DataFrame
        """
        target_bars = self._period_to_bars(period, timeframe)
        ms_per_bar = self._timeframe_to_minutes(timeframe) * 60 * 1000
        now_ms = self.exchange.milliseconds()
        since = now_ms - target_bars * ms_per_bar

        all_rows = []
        fetched = 0
        
        while True:
            ohlcv = self.exchange.fetch_ohlcv(symbol, timeframe=timeframe, since=since, limit=1500)
            if not ohlcv:
                break
            
            all_rows.extend(ohlcv)
            fetched += len(ohlcv)
            since = ohlcv[-1][0] + 1
            
            if len(ohlcv) < 1500 or fetched >= target_bars:
                break
            
            # è¯·æ±‚é—´éš”ï¼šæ·»åŠ  1.5 ç§’å»¶è¿Ÿï¼Œç¡®ä¿å³ä½¿ ccxt å†…éƒ¨å‘èµ·å¤šæ¬¡è¯·æ±‚ä¹Ÿæœ‰è¶³å¤Ÿé—´éš”
            # å¯¹ Hyperliquid æ¥è¯´ï¼Œ1.5 ç§’æ˜¯å®‰å…¨çš„é—´éš”
            time.sleep(1.5)

        if not all_rows:
            logger.debug(f"äº¤æ˜“å¯¹æ— å†å²æ•°æ®ï¼ˆAPIè¿”å›ç©ºåˆ—è¡¨ï¼‰| å¸ç§: {symbol} | {timeframe}/{period}")
            return pd.DataFrame(columns=["Open", "High", "Low", "Close", "Volume", "return", "volume_usd"])

        df = pd.DataFrame(all_rows, columns=["Timestamp", "Open", "High", "Low", "Close", "Volume"])
        df["Timestamp"] = pd.to_datetime(df["Timestamp"], unit="ms", utc=True).dt.tz_convert(None)
        df = df.set_index("Timestamp").sort_index()
        df['return'] = df['Close'].pct_change().fillna(0)
        df['volume_usd'] = df['Volume'] * df['Close']
        
        return df
    
    @staticmethod
    def _winsorize_returns(returns, lower_p=None, upper_p=None, log_stats=True):
        """
        Winsorization å¼‚å¸¸å€¼å¤„ç†

        å°†æ”¶ç›Šç‡æ•°ç»„ä¸­çš„æç«¯å€¼é™åˆ¶åœ¨æŒ‡å®šåˆ†ä½æ•°èŒƒå›´å†…ï¼Œæé«˜ç»Ÿè®¡åˆ†æçš„ç¨³å¥æ€§ã€‚

        Args:
            returns: æ”¶ç›Šç‡æ•°ç»„ï¼ˆnumpy arrayï¼‰
            lower_p: ä¸‹åˆ†ä½æ•°ï¼ˆé»˜è®¤ä½¿ç”¨ç±»å¸¸é‡ WINSORIZE_LOWER_PERCENTILEï¼‰
            upper_p: ä¸Šåˆ†ä½æ•°ï¼ˆé»˜è®¤ä½¿ç”¨ç±»å¸¸é‡ WINSORIZE_UPPER_PERCENTILEï¼‰
            log_stats: æ˜¯å¦è®°å½•ç»Ÿè®¡ä¿¡æ¯åˆ°æ—¥å¿—ï¼ˆé»˜è®¤ Falseï¼‰

        Returns:
            å¤„ç†åçš„æ”¶ç›Šç‡æ•°ç»„ï¼ˆnumpy arrayï¼‰

        Note:
            - å¦‚æœæ•°æ®ç‚¹å°‘äº 20 ä¸ªï¼Œä¸è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†ï¼ˆè¿”å›åŸæ•°ç»„ï¼‰
            - ä½¿ç”¨ np.clip è¿›è¡Œå¿«é€Ÿå¤„ç†
            - å¼‚å¸¸å€¼ä¼šè¢«é™åˆ¶åœ¨åˆ†ä½æ•°è¾¹ç•Œå†…ï¼Œè€Œä¸æ˜¯åˆ é™¤
        """
        # 1. å‚æ•°é»˜è®¤å€¼å¤„ç†
        if lower_p is None:
            lower_p = DelayCorrelationAnalyzer.WINSORIZE_LOWER_PERCENTILE
        if upper_p is None:
            upper_p = DelayCorrelationAnalyzer.WINSORIZE_UPPER_PERCENTILE

        # 2. æ•°æ®é‡æ£€æŸ¥ï¼šå¦‚æœæ•°æ®ç‚¹å¤ªå°‘ï¼Œä¸è¿›è¡Œå¼‚å¸¸å€¼å¤„ç†
        if len(returns) < 20:
            return returns

        # 3. è®¡ç®—åˆ†ä½æ•°è¾¹ç•Œ
        lower_bound = np.percentile(returns, lower_p)
        upper_bound = np.percentile(returns, upper_p)

        # 4. ç»Ÿè®¡å¼‚å¸¸å€¼æ•°é‡ï¼ˆç”¨äºæ—¥å¿—å’Œè°ƒè¯•ï¼‰
        n_lower_outliers = np.sum(returns < lower_bound)
        n_upper_outliers = np.sum(returns > upper_bound)
        total_outliers = n_lower_outliers + n_upper_outliers

        # 6. Winsorizationï¼šå°†æç«¯å€¼é™åˆ¶åœ¨åˆ†ä½æ•°èŒƒå›´å†…
        winsorized = np.clip(returns, lower_bound, upper_bound)

        # 6. è®°å½•ç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if log_stats and total_outliers > 0:
            logger.info(
                f"å¼‚å¸¸å€¼å¤„ç†ç»Ÿè®¡ | "
                f"ä¸‹ä¾§å¼‚å¸¸å€¼æ•°é‡: {n_lower_outliers} | "
                f"ä¸Šä¾§å¼‚å¸¸å€¼æ•°é‡: {n_upper_outliers} | "
                f"åˆ†ä½æ•°èŒƒå›´: [{lower_bound:.6f}, {upper_bound:.6f}] | "
                f"åŸå§‹æ•°æ®èŒƒå›´: [{np.min(returns):.6f}, {np.max(returns):.6f}] | "
                f"å¤„ç†åæ•°æ®èŒƒå›´: [{np.min(winsorized):.6f}, {np.max(winsorized):.6f}]"
            )

        return winsorized

    @staticmethod
    def _calculate_beta(btc_ret, alt_ret):
        """
        è®¡ç®— Beta ç³»æ•°

        è¡¡é‡å±±å¯¨å¸æ”¶ç›Šç‡ç›¸å¯¹äº BTC æ”¶ç›Šç‡çš„è·Ÿéšå¹…åº¦ã€‚

        Args:
            btc_ret: BTC æ”¶ç›Šç‡æ•°ç»„ï¼ˆnumpy arrayï¼‰
            alt_ret: å±±å¯¨å¸æ”¶ç›Šç‡æ•°ç»„ï¼ˆnumpy arrayï¼‰

        Returns:
            float: Beta ç³»æ•°å€¼
                - Beta > 1.0: ALT æ³¢åŠ¨å¹…åº¦å¤§äº BTC
                - Beta = 1.0: ALT ä¸ BTC åŒæ­¥æ³¢åŠ¨
                - Beta < 1.0: ALT æ³¢åŠ¨å¹…åº¦å°äº BTC
                - Beta < 0: ALT ä¸ BTC åå‘æ³¢åŠ¨ï¼ˆç½•è§ï¼‰
                - å¦‚æœæ•°æ®ä¸è¶³æˆ–è®¡ç®—å¤±è´¥ï¼Œè¿”å› np.nan

        Note:
            - Beta ç³»æ•°éœ€è¦è‡³å°‘ MIN_POINTS_FOR_BETA_CALC ä¸ªæ•°æ®ç‚¹
            - å¦‚æœ BTC æ”¶ç›Šç‡æ–¹å·®ä¸º 0ï¼Œè¿”å› np.nan
        """
        # 1. æ•°æ®é•¿åº¦æ£€æŸ¥
        if len(btc_ret) != len(alt_ret):
            logger.warning(f"Beta è®¡ç®—å¤±è´¥ï¼šBTC å’Œ ALT æ•°æ®é•¿åº¦ä¸ä¸€è‡´ | "
                          f"BTC: {len(btc_ret)}, ALT: {len(alt_ret)}")
            return np.nan

        # 2. æœ€å°æ•°æ®ç‚¹æ£€æŸ¥
        if len(btc_ret) < DelayCorrelationAnalyzer.MIN_POINTS_FOR_BETA_CALC:
            return np.nan

        # 3. è®¡ç®—åæ–¹å·®å’Œæ–¹å·®
        try:
            # ä½¿ç”¨ numpy çš„ cov å‡½æ•°è®¡ç®—åæ–¹å·®çŸ©é˜µ
            # cov_matrix[0, 1] æ˜¯ BTC å’Œ ALT çš„åæ–¹å·®
            # cov_matrix[0, 0] æ˜¯ BTC çš„æ–¹å·®
            cov_matrix = np.cov(btc_ret, alt_ret)
            covariance = cov_matrix[0, 1]
            btc_variance = cov_matrix[0, 0]

            # 4. æ£€æŸ¥ BTC æ–¹å·®æ˜¯å¦ä¸º 0ï¼ˆé¿å…é™¤ä»¥ 0ï¼‰
            if btc_variance == 0 or np.isnan(btc_variance):
                logger.debug("Beta è®¡ç®—å¤±è´¥ï¼šBTC æ”¶ç›Šç‡æ–¹å·®ä¸º 0 æˆ– NaN")
                return np.nan

            # 5. è®¡ç®— Beta ç³»æ•°
            beta = covariance / btc_variance

            # 6. æ£€æŸ¥ç»“æœæœ‰æ•ˆæ€§
            if np.isnan(beta) or np.isinf(beta):
                logger.debug(f"Beta è®¡ç®—å¤±è´¥ï¼šç»“æœä¸º NaN æˆ– Inf | Beta: {beta}")
                return np.nan

            return beta

        except Exception as e:
            logger.warning(f"Beta è®¡ç®—å¼‚å¸¸ï¼š{type(e).__name__}: {str(e)}")
            return np.nan
    
    @staticmethod
    def _calculate_zscore(btc_prices: pd.Series, alt_prices: pd.Series, 
                          beta: float, window: int = 20) -> float | None:
        """
        è®¡ç®—ä»·å·®çš„ Z-scoreï¼ˆç”¨äºé‡åŒ–å¥—åˆ©æœºä¼šçš„ä¿¡å·å¼ºåº¦ï¼‰

        é€šè¿‡æ„å»ºä»·å·®åºåˆ—ï¼ˆspread = alt_prices - Î² Ã— btc_pricesï¼‰ï¼Œ
        è®¡ç®—å½“å‰ä»·å·®ç›¸å¯¹äºå†å²å‡å€¼çš„åç¦»ç¨‹åº¦ï¼ˆä»¥æ ‡å‡†å·®ä¸ºå•ä½ï¼‰ã€‚

        Args:
            btc_prices: BTC ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
            alt_prices: å±±å¯¨å¸ä»·æ ¼åºåˆ—ï¼ˆpandas Seriesï¼‰
            beta: Beta ç³»æ•°ï¼ˆç”¨äºæ„å»ºä»·å·®ï¼‰
            window: æ»šåŠ¨çª—å£å¤§å°ï¼ˆé»˜è®¤ 20ï¼‰

        Returns:
            float: å½“å‰ Z-score å€¼
                - |Z-score| > 2: æ˜¾è‘—åç¦»ï¼ˆå¼ºå¥—åˆ©ä¿¡å·ï¼‰
                - |Z-score| > 1: ä¸­ç­‰åç¦»
                - |Z-score| < 1: æ­£å¸¸æ³¢åŠ¨èŒƒå›´
            None: å¦‚æœæ•°æ®ä¸è¶³æˆ–è®¡ç®—å¤±è´¥

        Note:
            - éœ€è¦è‡³å°‘ window ä¸ªæ•°æ®ç‚¹æ‰èƒ½è®¡ç®— Z-score
            - Beta ç³»æ•°åº”è¯¥åŸºäºä»·æ ¼åºåˆ—è®¡ç®—ï¼ˆè€Œéæ”¶ç›Šç‡ï¼‰
            - å¦‚æœä»·å·®åºåˆ—çš„æ ‡å‡†å·®ä¸º 0ï¼Œè¿”å› None
        """
        # 1. æ•°æ®é•¿åº¦æ£€æŸ¥
        if len(btc_prices) != len(alt_prices):
            logger.warning(f"Z-score è®¡ç®—å¤±è´¥ï¼šBTC å’Œ ALT æ•°æ®é•¿åº¦ä¸ä¸€è‡´ | "
                          f"BTC: {len(btc_prices)}, ALT: {len(alt_prices)}")
            return None

        # 2. æœ€å°æ•°æ®ç‚¹æ£€æŸ¥
        if len(btc_prices) < window:
            logger.debug(f"Z-score è®¡ç®—å¤±è´¥ï¼šæ•°æ®ç‚¹ä¸è¶³ | éœ€è¦: {window}, å®é™…: {len(btc_prices)}")
            return None

        # 3. Beta æœ‰æ•ˆæ€§æ£€æŸ¥
        if np.isnan(beta) or np.isinf(beta) or beta == 0:
            logger.debug(f"Z-score è®¡ç®—å¤±è´¥ï¼šBeta ç³»æ•°æ— æ•ˆ | Beta: {beta}")
            return None

        try:
            # 4. æ„å»ºä»·å·®åºåˆ—ï¼šspread = alt_prices - Î² Ã— btc_prices
            spread = alt_prices - beta * btc_prices

            # 5. è®¡ç®—æ»šåŠ¨å‡å€¼å’Œæ ‡å‡†å·®
            spread_mean = spread.rolling(window=window, min_periods=window).mean()
            spread_std = spread.rolling(window=window, min_periods=window).std()

            # 6. æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æœ‰æ•ˆæ•°æ®
            if pd.isna(spread_mean.iloc[-1]) or pd.isna(spread_std.iloc[-1]):
                logger.debug("Z-score è®¡ç®—å¤±è´¥ï¼šæ»šåŠ¨ç»Ÿè®¡é‡åŒ…å« NaN")
                return None

            # 7. æ£€æŸ¥æ ‡å‡†å·®æ˜¯å¦ä¸º 0ï¼ˆé¿å…é™¤ä»¥ 0ï¼‰
            if spread_std.iloc[-1] == 0 or np.isnan(spread_std.iloc[-1]):
                logger.debug("Z-score è®¡ç®—å¤±è´¥ï¼šä»·å·®åºåˆ—æ ‡å‡†å·®ä¸º 0 æˆ– NaN")
                return None

            # 8. è®¡ç®—å½“å‰ Z-score
            current_spread = spread.iloc[-1]
            current_mean = spread_mean.iloc[-1]
            current_std = spread_std.iloc[-1]
            zscore = (current_spread - current_mean) / current_std

            # 9. æ£€æŸ¥ç»“æœæœ‰æ•ˆæ€§
            if np.isnan(zscore) or np.isinf(zscore):
                logger.debug(f"Z-score è®¡ç®—å¤±è´¥ï¼šç»“æœä¸º NaN æˆ– Inf | Z-score: {zscore}")
                return None

            return float(zscore)

        except Exception as e:
            logger.warning(f"Z-score è®¡ç®—å¼‚å¸¸ï¼š{type(e).__name__}: {str(e)}")
            return None

    @staticmethod
    def find_optimal_delay(btc_ret, alt_ret, max_lag=3,
                           enable_outlier_treatment=None,
                           enable_beta_calc=None):
        """
        å¯»æ‰¾æœ€ä¼˜å»¶è¿Ÿ Ï„*ï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒå¼‚å¸¸å€¼å¤„ç†å’Œ Beta ç³»æ•°è®¡ç®—ï¼‰

        é€šè¿‡è®¡ç®—ä¸åŒå»¶è¿Ÿä¸‹BTCå’Œå±±å¯¨å¸æ”¶ç›Šç‡çš„ç›¸å…³ç³»æ•°ï¼Œæ‰¾å‡ºä½¿ç›¸å…³ç³»æ•°æœ€å¤§çš„å»¶è¿Ÿå€¼ã€‚
        tau_star > 0 è¡¨ç¤ºå±±å¯¨å¸æ»åäºBTCï¼Œå­˜åœ¨æ—¶é—´å·®å¥—åˆ©æœºä¼šã€‚

        Args:
            btc_ret: BTCæ”¶ç›Šç‡æ•°ç»„
            alt_ret: å±±å¯¨å¸æ”¶ç›Šç‡æ•°ç»„
            max_lag: æœ€å¤§å»¶è¿Ÿå€¼ï¼ˆé»˜è®¤ 3ï¼‰
            enable_outlier_treatment: æ˜¯å¦å¯ç”¨å¼‚å¸¸å€¼å¤„ç†ï¼ˆNone æ—¶ä½¿ç”¨ç±»å¸¸é‡ï¼‰
            enable_beta_calc: æ˜¯å¦è®¡ç®— Beta ç³»æ•°ï¼ˆNone æ—¶ä½¿ç”¨ç±»å¸¸é‡ï¼‰

        Returns:
            tuple: (tau_star, corrs, max_related_matrix, beta)
                - tau_star: æœ€ä¼˜å»¶è¿Ÿå€¼
                - corrs: æ‰€æœ‰å»¶è¿Ÿå€¼å¯¹åº”çš„ç›¸å…³ç³»æ•°åˆ—è¡¨
                - max_related_matrix: æœ€å¤§ç›¸å…³ç³»æ•°
                - beta: Beta ç³»æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ– None
        """
        # ========== 1. å‚æ•°é»˜è®¤å€¼å¤„ç† ==========
        if enable_outlier_treatment is None:
            enable_outlier_treatment = DelayCorrelationAnalyzer.ENABLE_OUTLIER_TREATMENT
        if enable_beta_calc is None:
            enable_beta_calc = DelayCorrelationAnalyzer.ENABLE_BETA_CALCULATION

        # ========== 2. å¼‚å¸¸å€¼å¤„ç†ï¼ˆå¦‚æœå¯ç”¨ï¼‰==========
        if enable_outlier_treatment:
            btc_ret_processed = DelayCorrelationAnalyzer._winsorize_returns(
                btc_ret
            )
            alt_ret_processed = DelayCorrelationAnalyzer._winsorize_returns(
                alt_ret
            )
        else:
            btc_ret_processed = btc_ret
            alt_ret_processed = alt_ret

        # ========== 3. åŸæœ‰é€»è¾‘ï¼šè®¡ç®—ç›¸å…³ç³»æ•°å’Œæœ€ä¼˜å»¶è¿Ÿ ==========
        corrs = []
        lags = list(range(0, max_lag + 1))
        arr_len = len(btc_ret_processed)

        for lag in lags:
            # æ£€æŸ¥ lag æ˜¯å¦è¶…è¿‡æ•°ç»„é•¿åº¦ï¼Œé¿å…ç©ºæ•°ç»„åˆ‡ç‰‡
            if lag > 0 and lag >= arr_len:
                corrs.append(np.nan)
                continue

            if lag > 0:
                # ALTæ»åBTC: æ¯”è¾ƒ BTC[t] ä¸ ALT[t+lag]
                x = btc_ret_processed[:-lag]
                y = alt_ret_processed[lag:]
            else:
                x = btc_ret_processed
                y = alt_ret_processed

            m = min(len(x), len(y))

            if m < DelayCorrelationAnalyzer.MIN_POINTS_FOR_CORR_CALC:
                corrs.append(np.nan)
                continue

            related_matrix = np.corrcoef(x[:m], y[:m])[0, 1]
            corrs.append(np.nan if np.isnan(related_matrix) else related_matrix)

        # æ‰¾å‡ºæœ€å¤§ç›¸å…³ç³»æ•°å¯¹åº”çš„å»¶è¿Ÿå€¼ï¼ˆåŒ¹é…æ€§æœ€å¥½çš„å»¶è¿Ÿçª—å£é•¿åº¦ï¼‰
        valid_corrs = np.array(corrs)
        valid_mask = ~np.isnan(valid_corrs)
        if valid_mask.any():
            valid_indices = np.where(valid_mask)[0]
            best_idx = valid_indices[np.argmax(valid_corrs[valid_mask])]
            tau_star = lags[best_idx]
            max_related_matrix = valid_corrs[best_idx]
        else:
            tau_star = 0
            max_related_matrix = np.nan

        # ========== 4. è®¡ç®— Beta ç³»æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰==========
        beta = None
        if enable_beta_calc:
            # æ ¹æ®æœ€ä¼˜å»¶è¿Ÿé€‰æ‹©æ•°æ®å¯¹é½æ–¹å¼è®¡ç®— Beta
            # å¦‚æœæœ€ä¼˜å»¶è¿Ÿ > 0ï¼Œä½¿ç”¨å»¶è¿Ÿå¯¹é½åçš„æ•°æ®ï¼Œä»¥åæ˜ çœŸå®çš„è·Ÿéšå…³ç³»
            # å¦‚æœæœ€ä¼˜å»¶è¿Ÿ = 0ï¼Œä½¿ç”¨åŒæœŸæ•°æ®
            if tau_star > 0:
                # ä½¿ç”¨æœ€ä¼˜å»¶è¿Ÿå¯¹é½åçš„æ•°æ®ï¼šBTC[t] ä¸ ALT[t+tau_star]
                btc_beta = btc_ret_processed[:-tau_star]
                alt_beta = alt_ret_processed[tau_star:]
            else:
                # ä½¿ç”¨åŒæœŸæ•°æ®ï¼šBTC[t] ä¸ ALT[t]
                btc_beta = btc_ret_processed
                alt_beta = alt_ret_processed
            
            m_beta = min(len(btc_beta), len(alt_beta))
            if m_beta >= DelayCorrelationAnalyzer.MIN_POINTS_FOR_BETA_CALC:
                beta = DelayCorrelationAnalyzer._calculate_beta(
                    btc_beta[:m_beta],
                    alt_beta[:m_beta]
                )

        return tau_star, corrs, max_related_matrix, beta
    
    def _get_btc_data(self, timeframe: str, period: str) -> pd.DataFrame | None:
        """è·å–BTCæ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        cache_key = (timeframe, period)
        if cache_key in self.btc_df_cache:
            logger.debug(f"BTCæ•°æ®ç¼“å­˜å‘½ä¸­ | {timeframe}/{period}")
            return self.btc_df_cache[cache_key].copy()
        
        logger.debug(f"BTCæ•°æ®ç¼“å­˜æœªå‘½ä¸­ï¼Œå¼€å§‹ä¸‹è½½ | {timeframe}/{period}")
        btc_df = self._safe_download(self.btc_symbol, period, timeframe)
        if btc_df is None:
            return None
        self.btc_df_cache[cache_key] = btc_df
        return btc_df.copy()
    
    def _get_alt_data(self, symbol: str, period: str, timeframe: str, coin: str = None) -> pd.DataFrame | None:
        """
        è·å–å±±å¯¨å¸æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰
        
        Args:
            symbol: äº¤æ˜“å¯¹åç§°
            period: æ•°æ®å‘¨æœŸ
            timeframe: Kçº¿æ—¶é—´å‘¨æœŸ
            coin: ç”¨äºæ—¥å¿—çš„å¸ç§åç§°ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æˆåŠŸè¿”å›DataFrameï¼Œå¤±è´¥è¿”å›None
        """
        display_name = coin or symbol
        cache_key = (symbol, timeframe, period)
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self.alt_df_cache:
            cached_df = self.alt_df_cache[cache_key]
            # éªŒè¯ç¼“å­˜çš„æ•°æ®æ˜¯å¦ä¸ºç©º
            if cached_df.empty or len(cached_df) == 0:
                logger.warning(f"å±±å¯¨å¸æ•°æ®ç¼“å­˜å‘½ä¸­ä½†æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ | å¸ç§: {display_name} | {timeframe}/{period}")
                return None
            logger.debug(f"å±±å¯¨å¸æ•°æ®ç¼“å­˜å‘½ä¸­ | å¸ç§: {display_name} | {timeframe}/{period}")
            return cached_df.copy()
        
        # ç›´æ¥ä¸‹è½½å¹¶ç¼“å­˜
        logger.debug(f"å±±å¯¨å¸æ•°æ®ç¼“å­˜æœªå‘½ä¸­ï¼Œå¼€å§‹ä¸‹è½½ | å¸ç§: {display_name} | {timeframe}/{period}")
        alt_df = self._safe_download(symbol, period, timeframe, coin)
        if alt_df is None:
            return None
        # éªŒè¯ä¸‹è½½çš„æ•°æ®æ˜¯å¦ä¸ºç©º
        if alt_df.empty or len(alt_df) == 0:
            logger.warning(f"å±±å¯¨å¸æ•°æ®ä¸å­˜åœ¨ï¼ˆç©ºæ•°æ®ï¼‰ï¼Œä¸ç¼“å­˜ | å¸ç§: {display_name} | {timeframe}/{period}")
            return None
        # éªŒè¯æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
        if len(alt_df) < self.MIN_DATA_POINTS_FOR_ANALYSIS:
            logger.warning(f"å±±å¯¨å¸æ•°æ®é‡ä¸è¶³ï¼Œä¸ç¼“å­˜ | å¸ç§: {display_name} | {timeframe}/{period} | æ•°æ®é‡: {len(alt_df)}")
            return None
        self.alt_df_cache[cache_key] = alt_df
        return alt_df.copy()
    
    @staticmethod
    def _safe_execute(func, *args, error_msg: str = None, log_error: bool = True, **kwargs):
        """
        å®‰å…¨æ‰§è¡Œå‡½æ•°ï¼Œç»Ÿä¸€é”™è¯¯å¤„ç†
        
        Args:
            func: è¦æ‰§è¡Œçš„å‡½æ•°
            *args: å‡½æ•°çš„ä½ç½®å‚æ•°
            error_msg: è‡ªå®šä¹‰é”™è¯¯æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
            log_error: æ˜¯å¦è®°å½•é”™è¯¯æ—¥å¿—ï¼ˆé»˜è®¤Trueï¼‰
            **kwargs: å‡½æ•°çš„å…³é”®å­—å‚æ•°
        
        Returns:
            å‡½æ•°è¿”å›å€¼ï¼Œå¦‚æœå‘ç”Ÿå¼‚å¸¸è¿”å› None
        """
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if log_error and error_msg:
                logger.warning(f"{error_msg} | {type(e).__name__}: {str(e)}")
            return None
    
    def _align_and_validate_data(self, btc_df: pd.DataFrame, alt_df: pd.DataFrame, 
                                  coin: str, timeframe: str, period: str) -> tuple[pd.DataFrame, pd.DataFrame] | None:
        """
        å¯¹é½å’ŒéªŒè¯BTCä¸å±±å¯¨å¸æ•°æ®
        
        Args:
            btc_df: BTCæ•°æ®DataFrame
            alt_df: å±±å¯¨å¸æ•°æ®DataFrame
            coin: å¸ç§åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
            timeframe: æ—¶é—´å‘¨æœŸ
            period: æ•°æ®å‘¨æœŸ
        
        Returns:
            æˆåŠŸè¿”å›å¯¹é½åçš„ (btc_df, alt_df)ï¼Œå¤±è´¥è¿”å› None
        """
        # æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨ï¼ˆåŒºåˆ†"æ•°æ®ä¸å­˜åœ¨"å’Œ"æ•°æ®é‡ä¸è¶³"ï¼‰
        if alt_df.empty or len(alt_df) == 0:
            logger.warning(f"æ•°æ®ä¸å­˜åœ¨ï¼ˆç©ºæ•°æ®ï¼‰ï¼Œè·³è¿‡ | å¸ç§: {coin} | {timeframe}/{period}")
            return None
        
        # å¯¹é½æ—¶é—´ç´¢å¼•
        common_idx = btc_df.index.intersection(alt_df.index)
        btc_df_aligned = btc_df.loc[common_idx]
        alt_df_aligned = alt_df.loc[common_idx]
        
        # æ•°æ®éªŒè¯ï¼šæ£€æŸ¥æ•°æ®é‡ï¼ˆæ•°æ®å­˜åœ¨ä½†ä¸è¶³ï¼‰
        if len(btc_df_aligned) < self.MIN_DATA_POINTS_FOR_ANALYSIS or len(alt_df_aligned) < self.MIN_DATA_POINTS_FOR_ANALYSIS:
            logger.warning(f"æ•°æ®é‡ä¸è¶³ï¼Œè·³è¿‡ | å¸ç§: {coin} | {timeframe}/{period} | BTCæ•°æ®é‡: {len(btc_df_aligned)} | å±±å¯¨å¸æ•°æ®é‡: {len(alt_df_aligned)}")
            logger.debug(f"å¸ç§: {coin} | {timeframe}/{period} æ•°æ®è¯¦æƒ… | BTC: {btc_df.head()}, length: {len(btc_df)} | å±±å¯¨å¸: {alt_df.head()}, length: {len(alt_df)}")
            return None
        
        return btc_df_aligned, alt_df_aligned
    
    def _analyze_single_combination(self, coin: str, timeframe: str, period: str, alt_df: pd.DataFrame | None = None) -> tuple | None:
        """
        åˆ†æå•ä¸ª timeframe/period ç»„åˆï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒ Beta ç³»æ•°ï¼‰

        Args:
            coin: å¸ç§äº¤æ˜“å¯¹åç§°
            timeframe: Kçº¿æ—¶é—´å‘¨æœŸ
            period: æ•°æ®å‘¨æœŸ
            alt_df: å¯é€‰çš„é¢„è·å–çš„å±±å¯¨å¸æ•°æ®ï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥ä½¿ç”¨ï¼Œå¦åˆ™è°ƒç”¨ _get_alt_data è·å–

        Returns:
            æˆåŠŸè¿”å› (correlation, timeframe, period, tau_star, beta)ï¼Œå¤±è´¥è¿”å› None
            æ³¨æ„ï¼šbeta å¯èƒ½ä¸º Noneï¼ˆå¦‚æœè®¡ç®—å¤±è´¥æˆ–ç¦ç”¨ï¼‰
        """
        btc_df = self._get_btc_data(timeframe, period)
        if btc_df is None:
            return None

        # å¦‚æœæä¾›äº†é¢„è·å–çš„æ•°æ®ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™è°ƒç”¨ _get_alt_data è·å–
        if alt_df is None:
            alt_df = self._get_alt_data(coin, period, timeframe, coin)
        if alt_df is None:
            return None

        # å¯¹é½å’ŒéªŒè¯æ•°æ®
        aligned_data = self._align_and_validate_data(btc_df, alt_df, coin, timeframe, period)
        if aligned_data is None:
            return None
        btc_df_aligned, alt_df_aligned = aligned_data

        # è°ƒç”¨å¢å¼ºç‰ˆçš„ find_optimal_delayï¼ˆç°åœ¨è¿”å› 4 ä¸ªå€¼ï¼‰
        tau_star, _, related_matrix, beta = self.find_optimal_delay(
            btc_df_aligned['return'].values,
            alt_df_aligned['return'].values
        )

        # å¢å¼ºæ—¥å¿—è¾“å‡º
        if beta is not None and not np.isnan(beta):
            logger.debug(
                f"åˆ†æä¸­é—´ç»“æœ | å¸ç§: {coin} | timeframe: {timeframe} | period: {period} | "
                f"tau_star: {tau_star} | ç›¸å…³ç³»æ•°: {related_matrix:.4f} | Beta: {beta:.4f}"
            )
        else:
            logger.debug(
                f"åˆ†æä¸­é—´ç»“æœ | å¸ç§: {coin} | timeframe: {timeframe} | period: {period} | "
                f"tau_star: {tau_star} | ç›¸å…³ç³»æ•°: {related_matrix:.4f}"
            )

        return (related_matrix, timeframe, period, tau_star, beta)
    
    def _detect_anomaly_pattern(self, results: list) -> tuple[bool, float, float, float]:
        """
        æ£€æµ‹å¼‚å¸¸æ¨¡å¼ï¼šçŸ­æœŸä½ç›¸å…³ä½†é•¿æœŸé«˜ç›¸å…³
        
        å¼‚å¸¸æ¨¡å¼åˆ¤æ–­é˜ˆå€¼ï¼š
        - é•¿æœŸç›¸å…³ç³»æ•° > LONG_TERM_CORR_THRESHOLDï¼šé•¿æœŸä¸BTCæœ‰è¾ƒå¼ºè·Ÿéšæ€§ï¼ˆ7då¯¹åº”5mï¼‰
        - çŸ­æœŸç›¸å…³ç³»æ•° < SHORT_TERM_CORR_THRESHOLDï¼šçŸ­æœŸå­˜åœ¨æ˜æ˜¾æ»åï¼ˆ1då¯¹åº”1mï¼‰
        - å·®å€¼ > CORR_DIFF_THRESHOLDï¼šçŸ­æœŸå’Œé•¿æœŸå·®å¼‚è¶³å¤Ÿæ˜¾è‘—
        - å¹³å‡Betaç³»æ•° >= AVG_BETA_THRESHOLDï¼šæ³¢åŠ¨å¹…åº¦éœ€æ»¡è¶³é˜ˆå€¼è¦æ±‚
        
        Returns:
            (is_anomaly, diff_amount, min_short_corr, max_long_corr): æ˜¯å¦å¼‚å¸¸æ¨¡å¼ã€ç›¸å…³ç³»æ•°å·®å€¼ã€çŸ­æœŸæœ€å°ç›¸å…³ç³»æ•°ã€é•¿æœŸæœ€å¤§ç›¸å…³ç³»æ•°
        """
        # ========== Beta ç³»æ•°æ£€æŸ¥ ==========
        # ä» results ä¸­æå–æ‰€æœ‰æœ‰æ•ˆçš„ beta å€¼
        valid_betas = []
        for result in results:
            # å¤„ç†æ–°æ—§æ ¼å¼å…¼å®¹ï¼ˆ5ä¸ªå€¼ vs 4ä¸ªå€¼ï¼‰
            if len(result) == 5:
                _, _, _, _, beta = result
                if beta is not None and not np.isnan(beta):
                    valid_betas.append(beta)
            elif len(result) == 4:
                # æ—§æ ¼å¼æ²¡æœ‰ betaï¼Œè·³è¿‡
                continue
        
        # å¦‚æœå¯ç”¨äº† Beta è®¡ç®—ä¸”æœ‰æœ‰æ•ˆçš„ Beta å€¼ï¼Œè¿›è¡Œé˜ˆå€¼æ£€æŸ¥
        if self.ENABLE_BETA_CALCULATION and valid_betas:
            avg_beta = np.mean(valid_betas)
            if avg_beta < self.AVG_BETA_THRESHOLD:
                logger.info(
                    f"Betaç³»æ•°ä¸æ»¡è¶³è¦æ±‚ï¼Œè¿‡æ»¤ | å¹³å‡Beta: {avg_beta:.4f} < {self.AVG_BETA_THRESHOLD}"
                )
                return False, 0, 0.0, 0.0
        
        short_periods = ['1d']
        long_periods = ['7d']
        diff_amount = 0
        is_anomaly = False
        
        # ä½¿ç”¨ç´¢å¼•è®¿é—®ï¼Œæ·»åŠ é•¿åº¦æ£€æŸ¥ä»¥ç¡®ä¿å®‰å…¨ï¼ˆå…¼å®¹4å…ƒç»„å’Œ5å…ƒç»„æ ¼å¼ï¼‰
        short_term_corrs = [x[0] for x in results if len(x) >= 3 and x[2] in short_periods]
        long_term_corrs = [x[0] for x in results if len(x) >= 3 and x[2] in long_periods]
        
        if not short_term_corrs or not long_term_corrs:
            return False, 0, 0.0, 0.0
        
        min_short_corr = min(short_term_corrs)
        max_long_corr = max(long_term_corrs)
        
        # é•¿æœŸç›¸å…³ç³»æ•°å¤§äºé˜ˆå€¼ï¼Œä¸”çŸ­æœŸç›¸å…³ç³»æ•°å°äºé˜ˆå€¼çš„æ—¶å€™ï¼Œæ‰è®¡ç®—å·®å€¼
        if max_long_corr > self.LONG_TERM_CORR_THRESHOLD and min_short_corr < self.SHORT_TERM_CORR_THRESHOLD:
            # ç›¸å…³æ€§å·®å€¼å¤§äºé˜ˆå€¼ï¼Œåˆ™è®¤ä¸ºå­˜åœ¨å¥—åˆ©æœºä¼š
            diff_amount = max_long_corr - min_short_corr
            if diff_amount > self.CORR_DIFF_THRESHOLD:
                is_anomaly = True
        # é•¿æœŸç›¸å…³ç³»æ•°å¤§äºé˜ˆå€¼ï¼Œä¸”çŸ­æœŸå­˜åœ¨æ˜æ˜¾æ»åæ—¶ï¼Œåˆ™è®¤ä¸ºå­˜åœ¨å¥—åˆ©æœºä¼š
        if max_long_corr > self.LONG_TERM_CORR_THRESHOLD:
            # x[3] æ˜¯æœ€ä¼˜å»¶è¿Ÿï¼Œx[2] æ˜¯æ•°æ®å‘¨æœŸ
            if any((x[3] > 0) for x in results if len(x) >= 4 and x[2] == '1d'):
                is_anomaly = True
        
        return is_anomaly, diff_amount, min_short_corr, max_long_corr
    
    def _output_results(self, coin: str, results: list, diff_amount: float, zscore: float | None = None):
        """
        è¾“å‡ºå¼‚å¸¸æ¨¡å¼çš„åˆ†æç»“æœï¼ˆå¢å¼ºç‰ˆï¼šåŒ…å« Beta ç³»æ•°å’Œ Z-scoreï¼‰
        
        Args:
            coin: å¸ç§åç§°
            results: åˆ†æç»“æœåˆ—è¡¨
            diff_amount: ç›¸å…³ç³»æ•°å·®å€¼
            zscore: Z-score å€¼ï¼ˆå¯é€‰ï¼‰
        """
        # æ„å»ºç»“æœ DataFrame
        data_rows = []
        has_beta = False  # æ ‡è®°æ˜¯å¦æœ‰æœ‰æ•ˆçš„Betaå€¼

        for result in results:
            # å¤„ç†æ–°æ—§æ ¼å¼å…¼å®¹ï¼ˆ5ä¸ªå€¼ vs 4ä¸ªå€¼ï¼‰
            if len(result) == 5:
                corr, tf, p, ts, beta = result
            elif len(result) == 4:
                corr, tf, p, ts = result
                beta = None
            else:
                # å¤„ç†å¼‚å¸¸æ ¼å¼ï¼Œè®°å½•æ—¥å¿—å¹¶è·³è¿‡
                logger.warning(f"ç»“æœæ ¼å¼å¼‚å¸¸ï¼Œè·³è¿‡ | å¸ç§: {coin} | ç»“æœé•¿åº¦: {len(result)} | ç»“æœ: {result}")
                continue

            row = {
                'ç›¸å…³ç³»æ•°': corr,
                'æ—¶é—´å‘¨æœŸ': tf,
                'æ•°æ®å‘¨æœŸ': p,
                'æœ€ä¼˜å»¶è¿Ÿ': ts
            }

            # æ·»åŠ  Beta ç³»æ•°åˆ—ï¼ˆå¦‚æœå­˜åœ¨ä¸”æœ‰æ•ˆï¼‰
            if beta is not None and not np.isnan(beta):
                row['Betaç³»æ•°'] = beta
                has_beta = True

            data_rows.append(row)

        df_results = pd.DataFrame(data_rows)

        logger.info(f"å‘ç°å¼‚å¸¸å¸ç§ | äº¤æ˜“æ‰€: {self.exchange_name} | å¸ç§: {coin} | å·®å€¼: {diff_amount:.2f}")

        # é£ä¹¦æ¶ˆæ¯å†…å®¹
        content = f"{self.exchange_name}\n\n{coin} ç›¸å…³ç³»æ•°åˆ†æç»“æœ\n{df_results.to_string(index=False)}\n"
        content += f"\nå·®å€¼: {diff_amount:.2f}"

        # å¦‚æœæœ‰Betaä¿¡æ¯ï¼Œæ·»åŠ é£é™©æç¤º
        if has_beta:
            avg_beta = df_results['Betaç³»æ•°'].mean() if 'Betaç³»æ•°' in df_results.columns else None
            if avg_beta is not None and avg_beta > 1.5:
                content += f"\nâš ï¸ é«˜æ³¢åŠ¨é£é™©ï¼šå¹³å‡Beta={avg_beta:.2f}ï¼ˆæ³¢åŠ¨å¹…åº¦æ˜¯BTCçš„{avg_beta:.1f}å€ï¼‰"
            elif avg_beta is not None and avg_beta > 1.2:
                content += f"\nâš ï¸ ä¸­ç­‰æ³¢åŠ¨ï¼šå¹³å‡Beta={avg_beta:.2f}"
            else:
                content += f"\nBetaç³»æ•°: {avg_beta:.2f}"
        
        # å¦‚æœæœ‰ Z-score ä¿¡æ¯ï¼Œæ·»åŠ ä¿¡å·å¼ºåº¦æç¤º
        if zscore is not None:
            abs_zscore = abs(zscore)
            if abs_zscore > 3:
                content += f"\nğŸ”¥ å¼ºå¥—åˆ©ä¿¡å·ï¼šZ-score={zscore:.2f}ï¼ˆåç¦»{abs_zscore:.1f}å€æ ‡å‡†å·®ï¼‰"
            elif abs_zscore > 2:
                content += f"\nğŸ“Š ä¸­ç­‰å¥—åˆ©ä¿¡å·ï¼šZ-score={zscore:.2f}ï¼ˆåç¦»{abs_zscore:.1f}å€æ ‡å‡†å·®ï¼‰"
            else:
                content += f"\nZ-score: {zscore:.2f}"

        logger.debug(f"è¯¦ç»†åˆ†æç»“æœ:\n{df_results.to_string(index=False)}")

        # åªæœ‰åœ¨ lark_hook æœ‰æ•ˆæ—¶æ‰å‘é€é£ä¹¦é€šçŸ¥
        if self.lark_hook:
            sender(content, self.lark_hook)
        else:
            logger.warning(f"é£ä¹¦é€šçŸ¥æœªå‘é€ï¼ˆLARKBOT_ID æœªé…ç½®ï¼‰| å¸ç§: {coin}")
    
    def one_coin_analysis(self, coin: str) -> bool:
        """
        åˆ†æå•ä¸ªå¸ç§ä¸BTCçš„ç›¸å…³ç³»æ•°ï¼Œè¯†åˆ«å¼‚å¸¸æ¨¡å¼ï¼ˆå¢å¼ºç‰ˆï¼šæ”¯æŒ Z-score éªŒè¯ï¼‰

        Args:
            coin: å¸ç§äº¤æ˜“å¯¹åç§°ï¼Œå¦‚ "ETH/USDC:USDC"

        Returns:
            æ˜¯å¦å‘ç°å¼‚å¸¸æ¨¡å¼
        """
        results = []
        first_alt_df = None  # ä¿å­˜ç¬¬ä¸€ä¸ªç»„åˆè·å–çš„æ•°æ®ï¼Œé¿å…é‡å¤è°ƒç”¨
        price_data_cache = {}  # ç¼“å­˜ä»·æ ¼æ•°æ®ï¼Œç”¨äº Z-score è®¡ç®—

        # ç›´æ¥éå†é¢„å®šä¹‰çš„ç»„åˆåˆ—è¡¨ï¼š5m/7d å’Œ 1m/1d
        for timeframe, period in self.combinations:
            # å°è¯•è·å–ç¬¬ä¸€ä¸ªç»„åˆçš„æ•°æ®ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç©º
            first_alt_df = self._get_alt_data(coin, period, timeframe, coin)
            if first_alt_df is None:
                # æ•°æ®ä¸å­˜åœ¨ï¼Œæå‰é€€å‡ºæ‰€æœ‰ç»„åˆ
                logger.warning(f"å¸ç§æ•°æ®ä¸å­˜åœ¨ï¼ˆç¬¬ä¸€ä¸ªç»„åˆæ£€æŸ¥æ— æ•°æ®ï¼‰ï¼Œè·³è¿‡åç»­æ‰€æœ‰ç»„åˆ | å¸ç§: {coin} | {timeframe}/{period}")
                return False
            
            # ç¼“å­˜ä»·æ ¼æ•°æ®ï¼ˆç”¨äº Z-score è®¡ç®—ï¼‰
            btc_df = self._get_btc_data(timeframe, period)
            if btc_df is not None:
                aligned_data = self._align_and_validate_data(btc_df, first_alt_df, coin, timeframe, period)
                if aligned_data is not None:
                    btc_aligned, alt_aligned = aligned_data
                    price_data_cache[(timeframe, period)] = {
                        'btc_prices': btc_aligned['Close'],
                        'alt_prices': alt_aligned['Close']
                    }
            
            # ä½¿ç”¨é¢„è·å–çš„æ•°æ®è¿›è¡Œåˆ†æï¼Œé¿å…é‡å¤è°ƒç”¨
            result = self._safe_execute(
                self._analyze_single_combination,
                coin, timeframe, period, first_alt_df,
                error_msg=f"å¤„ç† {coin} çš„ {timeframe}/{period} æ—¶å‘ç”Ÿå¼‚å¸¸"
            )
            if result is not None:
                results.append(result)

        # è¿‡æ»¤ NaN å¹¶æŒ‰ç›¸å…³ç³»æ•°é™åºæ’åºï¼ˆå¤„ç†æ–°çš„5å…ƒç»„æ ¼å¼ï¼‰
        valid_results = []
        for result in results:
            # å¤„ç†æ–°æ ¼å¼ï¼ˆ5ä¸ªå€¼ï¼‰
            if len(result) == 5:
                corr, tf, p, ts, beta = result
                if not np.isnan(corr):
                    valid_results.append((corr, tf, p, ts, beta))
            # å‘åå…¼å®¹æ—§æ ¼å¼ï¼ˆ4ä¸ªå€¼ï¼‰
            elif len(result) == 4:
                corr, tf, p, ts = result
                if not np.isnan(corr):
                    valid_results.append((corr, tf, p, ts, None))
            else:
                # å¤„ç†å¼‚å¸¸æ ¼å¼ï¼Œè®°å½•æ—¥å¿—å¹¶è·³è¿‡
                logger.warning(f"ç»“æœæ ¼å¼å¼‚å¸¸ï¼Œè·³è¿‡ | å¸ç§: {coin} | ç»“æœé•¿åº¦: {len(result)} | ç»“æœ: {result}")
                continue

        valid_results = sorted(valid_results, key=lambda x: x[0], reverse=True)

        if not valid_results:
            logger.warning(f"æ•°æ®ä¸è¶³ï¼Œæ— æ³•åˆ†æ | å¸ç§: {coin}")
            return False

        is_anomaly, diff_amount, min_short_corr, max_long_corr = self._detect_anomaly_pattern(valid_results)
        logger.info(
            f"ç›¸å…³ç³»æ•°æ£€æµ‹ | å¸ç§: {coin} | æ˜¯å¦å¼‚å¸¸: {is_anomaly} | å·®å€¼: {diff_amount:.4f} | çŸ­æœŸæœ€å°: {min_short_corr:.4f} | é•¿æœŸæœ€å¤§: {max_long_corr:.4f}"
            )

        # ========== Z-score éªŒè¯ï¼ˆå¦‚æœå¯ç”¨ä¸”æ£€æµ‹åˆ°å¼‚å¸¸ï¼‰==========
        zscore_result = None
        if is_anomaly and self.ENABLE_ZSCORE_CHECK:
            # ä¼˜å…ˆä½¿ç”¨çŸ­æœŸæ•°æ®ï¼ˆ1m/1dï¼‰è®¡ç®— Z-scoreï¼Œå› ä¸ºè¿™æ˜¯æ£€æµ‹å¼‚å¸¸çš„ä¸»è¦å‘¨æœŸ
            zscore_beta = None
            
            # å°è¯•ä»çŸ­æœŸæ•°æ®è®¡ç®— Z-score
            short_term_key = None
            for tf, p in self.combinations:
                if p == '1d':  # çŸ­æœŸå‘¨æœŸ
                    short_term_key = (tf, p)
                    break
            
            if short_term_key and short_term_key in price_data_cache:
                # ä» valid_results ä¸­è·å–å¯¹åº”çš„ beta
                for result in valid_results:
                    if len(result) >= 5:
                        corr, tf, p, ts, beta = result
                        if (tf, p) == short_term_key and beta is not None and not np.isnan(beta):
                            zscore_beta = beta
                            break
                
                # å¦‚æœæ‰¾åˆ°äº† betaï¼Œè®¡ç®— Z-score
                if zscore_beta is not None:
                    price_data = price_data_cache[short_term_key]
                    zscore_result = self._calculate_zscore(
                        price_data['btc_prices'],
                        price_data['alt_prices'],
                        zscore_beta,
                        window=self.ZSCORE_WINDOW
                    )
                    
                    if zscore_result is not None:
                        abs_zscore = abs(zscore_result)
                        if abs_zscore < self.ZSCORE_THRESHOLD:
                            logger.info(
                                f"Z-score éªŒè¯æœªé€šè¿‡ï¼Œè¿‡æ»¤ä¿¡å· | å¸ç§: {coin} | "
                                f"Z-score: {zscore_result:.2f} < {self.ZSCORE_THRESHOLD}"
                            )
                            return False
                        else:
                            logger.info(
                                f"Z-score éªŒè¯é€šè¿‡ | å¸ç§: {coin} | "
                                f"Z-score: {zscore_result:.2f} | ä¿¡å·å¼ºåº¦: {'å¼º' if abs_zscore > 3 else 'ä¸­ç­‰'}"
                            )
                    else:
                        logger.debug(f"Z-score è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡éªŒè¯ | å¸ç§: {coin}")
            else:
                logger.debug(f"æœªæ‰¾åˆ°ä»·æ ¼æ•°æ®ï¼Œè·³è¿‡ Z-score éªŒè¯ | å¸ç§: {coin}")

        if is_anomaly:
            self._output_results(coin, valid_results, diff_amount, zscore=zscore_result)
            return True
        else:
            # è®¡ç®—ç›¸å…³ç³»æ•°ç»Ÿè®¡ä¿¡æ¯
            corrs = [r[0] for r in valid_results]
            min_corr = min(corrs) if corrs else 0
            max_corr = max(corrs) if corrs else 0
            logger.info(f"å¸¸è§„æ•°æ® | å¸ç§: {coin} | ç›¸å…³ç³»æ•°èŒƒå›´: {min_corr:.4f} ~ {max_corr:.4f}")
            return False
    
    def run(self):
        """åˆ†æäº¤æ˜“æ‰€ä¸­æ‰€æœ‰USDCæ°¸ç»­åˆçº¦äº¤æ˜“å¯¹"""
        logger.info(f"å¯åŠ¨åˆ†æå™¨ | äº¤æ˜“æ‰€: {self.exchange_name} | "
                    f"Kçº¿ç»„åˆ: {self.combinations}")
        
        all_coins = self.exchange.load_markets()
        usdc_coins = [c for c in all_coins if '/USDC:USDC' in c and c != self.btc_symbol]
        total = len(usdc_coins)
        anomaly_count = 0
        skip_count = 0
        start_time = time.time()
        
        logger.info(f"å‘ç° {total} ä¸ª USDC æ°¸ç»­åˆçº¦äº¤æ˜“å¯¹")
        
        # è¿›åº¦é‡Œç¨‹ç¢‘ï¼š25%, 50%, 75%, 100%
        milestones = {max(1, int(total * p)) for p in [0.25, 0.5, 0.75, 1.0]}
        
        for idx, coin in enumerate(usdc_coins, 1):
            logger.debug(f"æ£€æŸ¥å¸ç§: {coin}")
            
            result = self._safe_execute(
                self.one_coin_analysis,
                coin,
                error_msg=f"åˆ†æå¸ç§ {coin} æ—¶å‘ç”Ÿé”™è¯¯"
            )
            if result is True:
                anomaly_count += 1
            elif result is None:
                skip_count += 1
            
            # åœ¨é‡Œç¨‹ç¢‘ä½ç½®æ‰“å°è¿›åº¦
            if idx in milestones:
                logger.info(f"åˆ†æè¿›åº¦: {idx}/{total} ({idx * 100 // total}%)")
            
            # å¸ç§ä¹‹é—´çš„é—´éš”ï¼šå¢åŠ åˆ° 2 ç§’ï¼Œé¿å…è§¦å‘ Hyperliquid çš„é™æµ
            time.sleep(2)
        
        elapsed = time.time() - start_time
        logger.info(
            f"åˆ†æå®Œæˆ | äº¤æ˜“æ‰€: {self.exchange_name} | "
            f"æ€»æ•°: {total} | å¼‚å¸¸: {anomaly_count} | è·³è¿‡: {skip_count} | "
            f"è€—æ—¶: {elapsed:.1f}s | å¹³å‡: {elapsed/total:.2f}s/å¸ç§"
        )


if __name__ == "__main__":
    analyzer = DelayCorrelationAnalyzer(exchange_name="hyperliquid")
    analyzer.run()
