# Hyperliquid BTC æ»åæ€§è¿½è¸ªå™¨ - æ”¹è¿›æ–¹æ¡ˆ

## ğŸ“‹ æ–‡æ¡£ä¿¡æ¯

- **åˆ›å»ºæ—¥æœŸ**: 2025-12-26
- **ç‰ˆæœ¬**: v1.0
- **ç›®æ ‡**: åŸºäºå­¦æœ¯ç ”ç©¶ä¼˜åŒ–ç»Ÿè®¡å¥—åˆ©ç­–ç•¥çš„ç†è®ºåŸºç¡€å’Œå®ç°æ–¹æ³•

## ğŸ¯ æ”¹è¿›ç›®æ ‡

åŸºäºä»¥ä¸‹ä¸¤ç¯‡æ–‡çŒ®çš„ç ”ç©¶æˆæœï¼Œä¼˜åŒ–å½“å‰é¡¹ç›®çš„åæ•´æ£€éªŒã€é£é™©è¯„ä¼°å’Œä¾èµ–å…³ç³»å»ºæ¨¡æ–¹æ³•ï¼š

1. **Leung & Nguyen (2019)**: ä½¿ç”¨ Engle-Granger å’Œ Johansen æ£€éªŒæ„å»ºåæ•´ç»„åˆ
2. **2025 æœ€æ–°ç ”ç©¶**: å¼•å…¥ Copula æ–¹æ³•ï¼Œåœ¨é£é™©è°ƒæ•´æ”¶ç›Šä¸Šä¼˜äºä¼ ç»Ÿç­–ç•¥

**æ ¸å¿ƒæ”¹è¿›æ–¹å‘**ï¼š
- âœ… ç”¨ç»Ÿè®¡å­¦ä¸¥è°¨çš„åæ•´æ£€éªŒæ›¿ä»£ç®€å•ç›¸å…³æ€§é˜ˆå€¼
- âœ… å¼•å…¥å¤šç»´åº¦é£é™©è°ƒæ•´æŒ‡æ ‡æ›¿ä»£å•ä¸€ Beta ç³»æ•°
- â¸ï¸ ï¼ˆå¯é€‰ï¼‰ä½¿ç”¨ Copula æ–¹æ³•æ•æ‰éçº¿æ€§ä¾èµ–å…³ç³»

---

## ğŸ” ç°çŠ¶åˆ†æ

### å½“å‰æ–¹æ³•çš„å±€é™æ€§

| ç»´åº¦ | å½“å‰å®ç° | å­˜åœ¨é—®é¢˜ | å½±å“ |
|-----|---------|---------|-----|
| **åæ•´å…³ç³»éªŒè¯** | ä½¿ç”¨çš®å°”é€Šç›¸å…³ç³»æ•° > 0.6 | é«˜ç›¸å…³æ€§ â‰  åæ•´å…³ç³»ï¼Œæ— æ³•ä¿è¯å‡å€¼å›å½’ | å‡é˜³æ€§ç‡é«˜ï¼Œç­–ç•¥å¤±æ•ˆé£é™©å¤§ |
| **ç»Ÿè®¡æ˜¾è‘—æ€§** | ç»éªŒæ€§é˜ˆå€¼ï¼ˆ0.6, 0.4, 0.38ï¼‰ | ç¼ºä¹ç»Ÿè®¡æ£€éªŒï¼Œç½®ä¿¡åº¦æœªçŸ¥ | æ— æ³•é‡åŒ–ç­–ç•¥å¯é æ€§ |
| **é£é™©è¯„ä¼°** | ä»…ä½¿ç”¨ Beta â‰¥ 1.0 | æœªè€ƒè™‘é£é™©è°ƒæ•´æ”¶ç›Šï¼Œå¯èƒ½é€‰å‡ºé«˜æ³¢åŠ¨ä½æ”¶ç›Šæ ‡çš„ | å®é™…ç›ˆåˆ©èƒ½åŠ›å·® |
| **ä¾èµ–å…³ç³»å»ºæ¨¡** | çº¿æ€§ç›¸å…³ç³»æ•° | æ— æ³•æ•æ‰å°¾éƒ¨ä¾èµ–å’Œéçº¿æ€§å…³ç³» | é”™è¿‡å¤æ‚å¸‚åœºç»“æ„ä¸‹çš„æœºä¼š |

### å…³é”®ä»£ç ä½ç½®

```python
# hyperliquid_analyzer.py

# âŒ é—®é¢˜1ï¼šç”¨ç›¸å…³æ€§æ›¿ä»£åæ•´æ£€éªŒ
LONG_TERM_CORR_THRESHOLD = 0.6  # ç¬¬72è¡Œ
SHORT_TERM_CORR_THRESHOLD = 0.4  # ç¬¬74è¡Œ

# âŒ é—®é¢˜2ï¼šå•ä¸€é£é™©æŒ‡æ ‡
AVG_BETA_THRESHOLD = 1  # ç¬¬92è¡Œ

# âŒ é—®é¢˜3ï¼šç¼ºå°‘ç»Ÿè®¡æ£€éªŒ
@staticmethod
def find_optimal_delay(btc_ret, alt_ret, max_lag=3, ...):
    # ç¬¬274-280è¡Œï¼šä»…ä½¿ç”¨ np.corrcoef() è®¡ç®—ç›¸å…³æ€§
    corrs = [np.corrcoef(btc_ret[:-tau if tau > 0 else None],
                         alt_ret[tau:])[0, 1] if tau > 0
             else np.corrcoef(btc_ret, alt_ret)[0, 1]
             for tau in range(max_lag + 1)]
```

---

## ğŸš€ æ”¹è¿›æ–¹æ¡ˆ

### æ”¹è¿›1ï¼šå¼•å…¥åæ•´æ£€éªŒï¼ˆé«˜ä¼˜å…ˆçº§ ğŸ”¥ğŸ”¥ğŸ”¥ï¼‰

#### ç†è®ºåŸºç¡€

**åæ•´ç†è®ºæ ¸å¿ƒ**ï¼š
- **å®šä¹‰**: ä¸¤ä¸ªéå¹³ç¨³åºåˆ—çš„çº¿æ€§ç»„åˆæ˜¯å¹³ç¨³çš„ï¼Œå³å­˜åœ¨ç¨³å®šçš„é•¿æœŸå‡è¡¡å…³ç³»
- **æ•°å­¦è¡¨è¾¾**: è‹¥ `Y_t = Î² * X_t + Îµ_t`ï¼Œä¸” `Îµ_t ~ I(0)` (å¹³ç¨³)ï¼Œåˆ™ X å’Œ Y åæ•´
- **ä¸ç›¸å…³æ€§çš„åŒºåˆ«**:
  - ç›¸å…³æ€§ï¼šè¡¡é‡åŒæ­¥æ³¢åŠ¨ç¨‹åº¦ï¼ˆçŸ­æœŸç‰¹å¾ï¼‰
  - åæ•´ï¼šè¡¡é‡é•¿æœŸå‡è¡¡å…³ç³»ï¼ˆå‡å€¼å›å½’åŸºç¡€ï¼‰

**Engle-Granger ä¸¤æ­¥æ³•**ï¼š
1. **ç¬¬ä¸€æ­¥**ï¼šOLS å›å½’å¾—åˆ°æ®‹å·® `Îµ_t = Y_t - Î² * X_t`
2. **ç¬¬äºŒæ­¥**ï¼šADF æ£€éªŒæ®‹å·®å¹³ç¨³æ€§ï¼Œè‹¥ p-value < 0.05 åˆ™æ‹’ç»"å­˜åœ¨å•ä½æ ¹"å‡è®¾ï¼Œç¡®è®¤åæ•´

#### ä»£ç å®ç°

**æ–°å¢æ¨¡å—**: `utils/cointegration.py`

```python
"""
åæ•´æ£€éªŒå·¥å…·æ¨¡å—
å®ç° Engle-Granger å’Œ Johansen åæ•´æ£€éªŒ
"""

import numpy as np
import pandas as pd
from statsmodels.tsa.stattools import coint, adfuller
from sklearn.linear_model import LinearRegression
from typing import Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class CointegrationAnalyzer:
    """åæ•´å…³ç³»åˆ†æå™¨"""

    # åæ•´æ£€éªŒæ˜¾è‘—æ€§æ°´å¹³
    SIGNIFICANCE_LEVEL = 0.05

    # åŠè¡°æœŸè®¡ç®—çš„æœ€å°æ ·æœ¬é‡
    MIN_SAMPLES_FOR_HALF_LIFE = 30

    @staticmethod
    def engle_granger_test(
        btc_prices: pd.Series,
        alt_prices: pd.Series,
        significance: float = 0.05
    ) -> Dict[str, any]:
        """
        Engle-Granger ä¸¤æ­¥æ³•åæ•´æ£€éªŒ

        Args:
            btc_prices: BTC ä»·æ ¼åºåˆ—ï¼ˆéæ”¶ç›Šç‡ï¼‰
            alt_prices: å±±å¯¨å¸ä»·æ ¼åºåˆ—
            significance: æ˜¾è‘—æ€§æ°´å¹³ï¼Œé»˜è®¤ 0.05

        Returns:
            dict: {
                'is_cointegrated': bool - æ˜¯å¦å­˜åœ¨åæ•´å…³ç³»,
                'p_value': float - åæ•´æ£€éªŒ p å€¼,
                'test_statistic': float - æ£€éªŒç»Ÿè®¡é‡,
                'spread': pd.Series - åæ•´æ®‹å·®ï¼ˆä»·å·®åºåˆ—ï¼‰,
                'hedge_ratio': float - å¯¹å†²æ¯”ç‡ Î²,
                'half_life': float - å‡å€¼å›å½’åŠè¡°æœŸï¼ˆå¤©ï¼‰,
                'adf_p_value': float - æ®‹å·® ADF æ£€éªŒ p å€¼
            }
        """
        try:
            # ç¡®ä¿æ•°æ®å¯¹é½
            if len(btc_prices) != len(alt_prices):
                raise ValueError("ä»·æ ¼åºåˆ—é•¿åº¦ä¸ä¸€è‡´")

            if len(btc_prices) < 50:
                logger.warning(f"æ•°æ®ç‚¹ä¸è¶³: {len(btc_prices)} < 50ï¼Œåæ•´æ£€éªŒå¯èƒ½ä¸å¯é ")

            # ç¬¬ä¸€æ­¥ï¼šåæ•´æ£€éªŒ
            score, p_value, crit_values = coint(btc_prices, alt_prices)

            # ç¬¬äºŒæ­¥ï¼šè®¡ç®—å¯¹å†²æ¯”ç‡å’Œä»·å·®
            model = LinearRegression()
            X = btc_prices.values.reshape(-1, 1)
            y = alt_prices.values
            model.fit(X, y)

            hedge_ratio = model.coef_[0]
            spread = alt_prices - model.predict(X)

            # ç¬¬ä¸‰æ­¥ï¼šADF æ£€éªŒæ®‹å·®å¹³ç¨³æ€§
            adf_stat, adf_p_value, _, _, adf_crit, _ = adfuller(spread, regression='c')

            # ç¬¬å››æ­¥ï¼šè®¡ç®—åŠè¡°æœŸ
            half_life = CointegrationAnalyzer._calculate_half_life(spread)

            result = {
                'is_cointegrated': p_value < significance,
                'p_value': p_value,
                'test_statistic': score,
                'spread': pd.Series(spread, index=alt_prices.index),
                'hedge_ratio': hedge_ratio,
                'half_life': half_life,
                'adf_p_value': adf_p_value,
                'adf_statistic': adf_stat,
                'critical_values': crit_values
            }

            logger.debug(
                f"åæ•´æ£€éªŒå®Œæˆ | p_value={p_value:.4f} | "
                f"åæ•´={result['is_cointegrated']} | åŠè¡°æœŸ={half_life:.2f}å¤©"
            )

            return result

        except Exception as e:
            logger.error(f"åæ•´æ£€éªŒå¤±è´¥: {str(e)}")
            return {
                'is_cointegrated': False,
                'p_value': 1.0,
                'error': str(e)
            }

    @staticmethod
    def _calculate_half_life(spread: np.ndarray) -> float:
        """
        è®¡ç®—å‡å€¼å›å½’åŠè¡°æœŸ

        ä½¿ç”¨ AR(1) æ¨¡å‹: spread_t = Î± + Ï * spread_{t-1} + Îµ_t
        åŠè¡°æœŸ = -ln(2) / ln(Ï)

        Args:
            spread: ä»·å·®åºåˆ—

        Returns:
            float: åŠè¡°æœŸï¼ˆä»¥æ•°æ®ç‚¹ä¸ºå•ä½ï¼Œå¯¹äº5åˆ†é’Ÿæ•°æ®éœ€è½¬æ¢ä¸ºå¤©ï¼‰
                  è‹¥æ— æ³•è®¡ç®—åˆ™è¿”å› np.inf
        """
        try:
            if len(spread) < CointegrationAnalyzer.MIN_SAMPLES_FOR_HALF_LIFE:
                return np.inf

            # æ„é€  AR(1) å›å½’
            spread_lag = spread[:-1]
            spread_diff = spread[1:] - spread[:-1]

            # OLS ä¼°è®¡: Î”spread_t = Î± + (Ï-1) * spread_{t-1} + Îµ_t
            model = LinearRegression()
            model.fit(spread_lag.reshape(-1, 1), spread_diff)

            # Ï = 1 + coef
            rho = 1 + model.coef_[0]

            # å‡å€¼å›å½’è¦æ±‚ 0 < Ï < 1
            if rho <= 0 or rho >= 1:
                logger.warning(f"å¼‚å¸¸ Ï å€¼: {rho:.4f}ï¼Œåºåˆ—å¯èƒ½ä¸æ»¡è¶³å‡å€¼å›å½’")
                return np.inf

            # åŠè¡°æœŸï¼ˆæ•°æ®ç‚¹æ•°ï¼‰
            half_life = -np.log(2) / np.log(rho)

            return half_life

        except Exception as e:
            logger.error(f"åŠè¡°æœŸè®¡ç®—å¤±è´¥: {str(e)}")
            return np.inf

    @staticmethod
    def convert_half_life_to_days(
        half_life_points: float,
        timeframe: str
    ) -> float:
        """
        å°†åŠè¡°æœŸä»æ•°æ®ç‚¹æ•°è½¬æ¢ä¸ºå¤©æ•°

        Args:
            half_life_points: ä»¥æ•°æ®ç‚¹ä¸ºå•ä½çš„åŠè¡°æœŸ
            timeframe: Kçº¿å‘¨æœŸ ('1m', '5m', '15m', '1h', '1d')

        Returns:
            float: ä»¥å¤©ä¸ºå•ä½çš„åŠè¡°æœŸ
        """
        # æ¯ä¸ªKçº¿å‘¨æœŸå¯¹åº”çš„åˆ†é’Ÿæ•°
        timeframe_minutes = {
            '1m': 1,
            '5m': 5,
            '15m': 15,
            '30m': 30,
            '1h': 60,
            '4h': 240,
            '1d': 1440
        }

        if timeframe not in timeframe_minutes:
            raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´å‘¨æœŸ: {timeframe}")

        minutes_per_point = timeframe_minutes[timeframe]
        days = (half_life_points * minutes_per_point) / (24 * 60)

        return days

    @staticmethod
    def zscore_spread(spread: pd.Series, window: int = 20) -> pd.Series:
        """
        è®¡ç®—ä»·å·®çš„ Z-Scoreï¼ˆç”¨äºç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼‰

        Args:
            spread: ä»·å·®åºåˆ—
            window: æ»šåŠ¨çª—å£å¤§å°

        Returns:
            pd.Series: Z-Score åºåˆ—
        """
        rolling_mean = spread.rolling(window=window).mean()
        rolling_std = spread.rolling(window=window).std()

        zscore = (spread - rolling_mean) / rolling_std
        return zscore


def test_cointegration_example():
    """
    ç¤ºä¾‹ï¼šåæ•´æ£€éªŒçš„ä½¿ç”¨æ–¹æ³•
    """
    # æ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    t = np.arange(1000)

    # ç”Ÿæˆåæ•´çš„ä»·æ ¼åºåˆ—
    btc_prices = pd.Series(100 + 0.05 * t + np.random.randn(1000) * 2)
    alt_prices = pd.Series(50 + 0.025 * t + btc_prices * 0.5 + np.random.randn(1000))

    # æ‰§è¡Œåæ•´æ£€éªŒ
    analyzer = CointegrationAnalyzer()
    result = analyzer.engle_granger_test(btc_prices, alt_prices)

    print(f"åæ•´å…³ç³»: {result['is_cointegrated']}")
    print(f"p-value: {result['p_value']:.4f}")
    print(f"å¯¹å†²æ¯”ç‡: {result['hedge_ratio']:.4f}")
    print(f"åŠè¡°æœŸ: {result['half_life']:.2f} ä¸ªæ•°æ®ç‚¹")

    # è½¬æ¢ä¸ºå¤©æ•°ï¼ˆå‡è®¾æ˜¯5åˆ†é’ŸKçº¿ï¼‰
    half_life_days = analyzer.convert_half_life_to_days(result['half_life'], '5m')
    print(f"åŠè¡°æœŸ: {half_life_days:.2f} å¤©")


if __name__ == '__main__':
    test_cointegration_example()
```

#### é›†æˆåˆ°ä¸»åˆ†æå™¨

**ä¿®æ”¹ `hyperliquid_analyzer.py`**:

```python
# åœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ å¯¼å…¥
from utils.cointegration import CointegrationAnalyzer

class DelayCorrelationAnalyzer:
    """
    å±±å¯¨å¸ä¸BTCç›¸å…³ç³»æ•°åˆ†æå™¨ï¼ˆæ”¹è¿›ç‰ˆï¼‰
    """

    # ========== æ–°å¢ï¼šåæ•´æ£€éªŒé…ç½® ==========
    # æ˜¯å¦å¯ç”¨åæ•´æ£€éªŒï¼ˆæ›¿ä»£ç®€å•ç›¸å…³æ€§é˜ˆå€¼ï¼‰
    ENABLE_COINTEGRATION_TEST = True
    # åæ•´æ£€éªŒçš„æ˜¾è‘—æ€§æ°´å¹³
    COINTEGRATION_SIGNIFICANCE = 0.05
    # æœ€å¤§å¯æ¥å—çš„åŠè¡°æœŸï¼ˆå¤©ï¼‰- è¶…è¿‡æ­¤å€¼è®¤ä¸ºå‡å€¼å›å½’è¿‡æ…¢
    MAX_HALF_LIFE_DAYS = 7

    # ä¿ç•™åŸé˜ˆå€¼ä½œä¸ºå¤‡ç”¨ï¼ˆå½“åæ•´æ£€éªŒå¤±è´¥æ—¶ï¼‰
    LONG_TERM_CORR_THRESHOLD = 0.6
    SHORT_TERM_CORR_THRESHOLD = 0.4
    CORR_DIFF_THRESHOLD = 0.38

    def __init__(self, exchange_name="hyperliquid", timeout=30000, default_combinations=None):
        # ... åŸæœ‰åˆå§‹åŒ–ä»£ç  ...

        # æ–°å¢ï¼šåæ•´åˆ†æå™¨
        self.coint_analyzer = CointegrationAnalyzer()

    def _test_long_term_relationship(
        self,
        btc_prices: pd.Series,
        alt_prices: pd.Series,
        timeframe: str
    ) -> Dict[str, any]:
        """
        æµ‹è¯•é•¿æœŸå…³ç³»ï¼ˆåæ•´æ£€éªŒ + ç›¸å…³æ€§ï¼‰

        Args:
            btc_prices: BTC ä»·æ ¼åºåˆ—
            alt_prices: å±±å¯¨å¸ä»·æ ¼åºåˆ—
            timeframe: Kçº¿å‘¨æœŸï¼ˆç”¨äºåŠè¡°æœŸè½¬æ¢ï¼‰

        Returns:
            dict: {
                'method': 'cointegration' | 'correlation',
                'is_valid': bool,
                'details': dict - æ£€éªŒè¯¦æƒ…
            }
        """
        if self.ENABLE_COINTEGRATION_TEST:
            # æ–¹æ³•1ï¼šåæ•´æ£€éªŒï¼ˆä¼˜å…ˆï¼‰
            coint_result = self.coint_analyzer.engle_granger_test(
                btc_prices,
                alt_prices,
                significance=self.COINTEGRATION_SIGNIFICANCE
            )

            # æ£€æŸ¥åŠè¡°æœŸæ˜¯å¦åœ¨å¯æ¥å—èŒƒå›´å†…
            if coint_result['is_cointegrated']:
                half_life_days = self.coint_analyzer.convert_half_life_to_days(
                    coint_result['half_life'],
                    timeframe
                )

                is_valid = (
                    half_life_days < self.MAX_HALF_LIFE_DAYS and
                    half_life_days > 0  # æ’é™¤å¼‚å¸¸å€¼
                )

                return {
                    'method': 'cointegration',
                    'is_valid': is_valid,
                    'details': {
                        **coint_result,
                        'half_life_days': half_life_days
                    }
                }

        # æ–¹æ³•2ï¼šç›¸å…³æ€§é˜ˆå€¼ï¼ˆå¤‡ç”¨ï¼‰
        btc_ret = btc_prices.pct_change().dropna()
        alt_ret = alt_prices.pct_change().dropna()

        if len(btc_ret) < self.MIN_POINTS_FOR_CORR_CALC:
            return {'method': 'correlation', 'is_valid': False}

        corr = np.corrcoef(btc_ret, alt_ret)[0, 1]

        return {
            'method': 'correlation',
            'is_valid': corr > self.LONG_TERM_CORR_THRESHOLD,
            'details': {'correlation': corr}
        }

    def one_coin_analysis(self, symbol: str) -> bool:
        """
        åˆ†æå•ä¸ªå¸ç§ï¼ˆæ”¹è¿›ç‰ˆï¼‰

        é›†æˆåæ•´æ£€éªŒå’Œé£é™©è°ƒæ•´æŒ‡æ ‡
        """
        try:
            coin = symbol.split('/')[0]
            logger.info(f"å¼€å§‹åˆ†æ | å¸ç§: {symbol}")

            results = []

            for timeframe, period in self.combinations:
                # è·å–ä»·æ ¼æ•°æ®ï¼ˆæ³¨æ„ï¼šéœ€è¦ä»·æ ¼è€Œéæ”¶ç›Šç‡ï¼‰
                btc_df = self._get_btc_data(timeframe, period)
                alt_df = self._get_alt_data(symbol, period, timeframe, coin)

                if btc_df is None or alt_df is None:
                    continue

                # æå–ä»·æ ¼åºåˆ—
                btc_prices = btc_df['close']
                alt_prices = alt_df['close']

                # ========== æ”¹è¿›1ï¼šåæ•´æ£€éªŒï¼ˆé•¿æœŸå…³ç³»ï¼‰ ==========
                if period == "7d":  # ä»…å¯¹é•¿æœŸæ•°æ®è¿›è¡Œåæ•´æ£€éªŒ
                    long_term_result = self._test_long_term_relationship(
                        btc_prices, alt_prices, timeframe
                    )

                    if not long_term_result['is_valid']:
                        logger.info(
                            f"é•¿æœŸå…³ç³»æ£€éªŒæœªé€šè¿‡ | å¸ç§: {symbol} | "
                            f"æ–¹æ³•: {long_term_result['method']}"
                        )
                        return False

                    # è®°å½•åæ•´ä¿¡æ¯ç”¨äºåç»­å‘Šè­¦
                    coint_info = long_term_result['details']

                # è®¡ç®—æ”¶ç›Šç‡ï¼ˆç”¨äºå»¶è¿Ÿåˆ†æï¼‰
                btc_ret = btc_prices.pct_change().dropna().values
                alt_ret = alt_prices.pct_change().dropna().values

                # å¯»æ‰¾æœ€ä¼˜å»¶è¿Ÿ
                tau_star, corrs, max_corr, beta = self.find_optimal_delay(
                    btc_ret, alt_ret,
                    max_lag=3,
                    enable_outlier_treatment=self.ENABLE_OUTLIER_TREATMENT,
                    enable_beta_calc=self.ENABLE_BETA_CALCULATION
                )

                results.append({
                    'timeframe': timeframe,
                    'period': period,
                    'tau_star': tau_star,
                    'max_corr': max_corr,
                    'beta': beta,
                    'coint_info': coint_info if period == "7d" else None
                })

            # ========== å¼‚å¸¸æ¨¡å¼æ£€æµ‹ï¼ˆæ”¹è¿›ç‰ˆï¼‰ ==========
            if len(results) >= 2:
                long_term = results[0]  # 7d
                short_term = results[1]  # 1d

                # ç»„åˆ1ï¼šè·¨å‘¨æœŸç›¸å…³æ€§ç ´è£‚ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
                corr_diff = long_term['max_corr'] - short_term['max_corr']
                avg_beta = np.mean([r['beta'] for r in results if r['beta'] is not None])

                condition1 = (
                    long_term['max_corr'] > self.LONG_TERM_CORR_THRESHOLD and
                    short_term['max_corr'] < self.SHORT_TERM_CORR_THRESHOLD and
                    corr_diff > self.CORR_DIFF_THRESHOLD and
                    avg_beta >= self.AVG_BETA_THRESHOLD
                )

                # ç»„åˆ2ï¼šå»¶è¿Ÿä¼ å¯¼æ¨¡å¼ï¼ˆä¿ç•™åŸé€»è¾‘ï¼‰
                condition2 = (
                    long_term['max_corr'] > self.LONG_TERM_CORR_THRESHOLD and
                    short_term['tau_star'] > 0 and
                    avg_beta >= self.AVG_BETA_THRESHOLD
                )

                if condition1 or condition2:
                    # ========== æ”¹è¿›2ï¼šå¢å¼ºå‘Šè­¦ä¿¡æ¯ ==========
                    self._send_enhanced_alert(
                        symbol, results, corr_diff, avg_beta,
                        coint_info=long_term.get('coint_info')
                    )
                    return True

            return False

        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥ | å¸ç§: {symbol} | é”™è¯¯: {str(e)}")
            return False

    def _send_enhanced_alert(
        self,
        symbol: str,
        results: list,
        corr_diff: float,
        avg_beta: float,
        coint_info: Optional[Dict] = None
    ):
        """
        å‘é€å¢å¼ºç‰ˆå‘Šè­¦ï¼ˆåŒ…å«åæ•´ä¿¡æ¯ï¼‰
        """
        # æ„å»ºè¡¨æ ¼
        table_header = "ç›¸å…³ç³»æ•°  æ—¶é—´å‘¨æœŸ  æ•°æ®å‘¨æœŸ  æœ€ä¼˜å»¶è¿Ÿ  Betaç³»æ•°\n"
        table_rows = "\n".join([
            f"  {r['max_corr']:.4f}      {r['timeframe']}      {r['period']}       "
            f"{r['tau_star']}     {r['beta']:.2f if r['beta'] else 'N/A'}"
            for r in results
        ])

        # åæ•´ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
        coint_section = ""
        if coint_info and coint_info.get('is_cointegrated'):
            coint_section = (
                f"\n\nğŸ“Š åæ•´æ£€éªŒ:\n"
                f"  âœ… é€šè¿‡ (p={coint_info['p_value']:.4f})\n"
                f"  å¯¹å†²æ¯”ç‡: {coint_info['hedge_ratio']:.4f}\n"
                f"  åŠè¡°æœŸ: {coint_info.get('half_life_days', 'N/A'):.2f} å¤©\n"
                f"  ADFç»Ÿè®¡é‡: {coint_info['adf_statistic']:.4f}"
            )

        # Beta é£é™©æç¤º
        if avg_beta >= 2.0:
            beta_warning = f"âš ï¸ é«˜é£é™©ï¼šå¹³å‡Beta={avg_beta:.2f}"
        elif avg_beta >= 1.5:
            beta_warning = f"âš ï¸ ä¸­ç­‰é£é™©ï¼šå¹³å‡Beta={avg_beta:.2f}"
        else:
            beta_warning = f"âœ… é€‚ä¸­æ³¢åŠ¨ï¼šå¹³å‡Beta={avg_beta:.2f}"

        message = (
            f"{self.exchange_name}\n\n"
            f"{symbol} ç›¸å…³ç³»æ•°åˆ†æç»“æœ\n"
            f"{table_header}{table_rows}\n\n"
            f"å·®å€¼: {corr_diff:.2f}\n"
            f"{beta_warning}"
            f"{coint_section}"
        )

        # å‘é€é£ä¹¦é€šçŸ¥
        sender(lark_bot_id, message)
        logger.info(f"å‘Šè­¦å·²å‘é€ | å¸ç§: {symbol} | å·®å€¼: {corr_diff:.2f}")
```

#### æµ‹è¯•ç”¨ä¾‹

**æ–°å¢æ–‡ä»¶**: `tests/test_cointegration.py`

```python
"""
åæ•´æ£€éªŒæ¨¡å—çš„å•å…ƒæµ‹è¯•
"""

import pytest
import numpy as np
import pandas as pd
from utils.cointegration import CointegrationAnalyzer


class TestCointegrationAnalyzer:

    def test_cointegrated_series(self):
        """æµ‹è¯•çœŸå®åæ•´åºåˆ—"""
        np.random.seed(42)
        t = np.arange(500)

        # ç”Ÿæˆåæ•´åºåˆ—
        btc = pd.Series(100 + 0.1 * t + np.random.randn(500))
        alt = pd.Series(50 + btc * 0.5 + np.random.randn(500) * 0.5)

        analyzer = CointegrationAnalyzer()
        result = analyzer.engle_granger_test(btc, alt)

        assert result['is_cointegrated'] == True
        assert result['p_value'] < 0.05
        assert 0 < result['half_life'] < 100

    def test_non_cointegrated_series(self):
        """æµ‹è¯•éåæ•´åºåˆ—"""
        np.random.seed(42)

        # ç”Ÿæˆç‹¬ç«‹éšæœºæ¸¸èµ°
        btc = pd.Series(np.cumsum(np.random.randn(500)))
        alt = pd.Series(np.cumsum(np.random.randn(500)))

        analyzer = CointegrationAnalyzer()
        result = analyzer.engle_granger_test(btc, alt)

        assert result['is_cointegrated'] == False
        assert result['p_value'] > 0.05

    def test_half_life_conversion(self):
        """æµ‹è¯•åŠè¡°æœŸå•ä½è½¬æ¢"""
        analyzer = CointegrationAnalyzer()

        # 5åˆ†é’ŸKçº¿ï¼Œ100ä¸ªç‚¹ = 500åˆ†é’Ÿ â‰ˆ 0.347å¤©
        days = analyzer.convert_half_life_to_days(100, '5m')
        assert abs(days - 0.347) < 0.01

        # 1å°æ—¶Kçº¿ï¼Œ24ä¸ªç‚¹ = 1å¤©
        days = analyzer.convert_half_life_to_days(24, '1h')
        assert abs(days - 1.0) < 0.01

    def test_insufficient_data(self):
        """æµ‹è¯•æ•°æ®ä¸è¶³çš„æƒ…å†µ"""
        btc = pd.Series(np.random.randn(30))
        alt = pd.Series(np.random.randn(30))

        analyzer = CointegrationAnalyzer()
        result = analyzer.engle_granger_test(btc, alt)

        # åº”è¯¥æœ‰è­¦å‘Šä½†ä¸åº”è¯¥å´©æºƒ
        assert 'p_value' in result


if __name__ == '__main__':
    pytest.main([__file__, '-v'])
```

---

### æ”¹è¿›2ï¼šé£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡ï¼ˆé«˜ä¼˜å…ˆçº§ ğŸ”¥ğŸ”¥ğŸ”¥ï¼‰

#### ç†è®ºåŸºç¡€

**å½“å‰é—®é¢˜**ï¼šå•ä¸€ Beta â‰¥ 1.0 é˜ˆå€¼æ— æ³•åŒºåˆ†ï¼š
- **æƒ…å†µA**: Î²=1.5, å¹´åŒ–æ”¶ç›Š20%, æœ€å¤§å›æ’¤-15% âœ… ä¼˜è´¨æ ‡çš„
- **æƒ…å†µB**: Î²=1.5, å¹´åŒ–æ”¶ç›Š5%, æœ€å¤§å›æ’¤-40% âŒ é«˜é£é™©ä½æ”¶ç›Š

**æ”¹è¿›ç›®æ ‡**ï¼šå¼•å…¥å¤šç»´åº¦é£é™©è°ƒæ•´æŒ‡æ ‡

| æŒ‡æ ‡ | å®šä¹‰ | æ„ä¹‰ |
|-----|-----|------|
| **å¤æ™®æ¯”ç‡** | (æ”¶ç›Šç‡ - æ— é£é™©åˆ©ç‡) / æ³¢åŠ¨ç‡ | å•ä½é£é™©çš„è¶…é¢æ”¶ç›Šï¼Œ>1.0 ä¸ºä¼˜ç§€ |
| **ç´¢æè¯ºæ¯”ç‡** | æ”¶ç›Šç‡ / ä¸‹è¡Œæ³¢åŠ¨ç‡ | åªæƒ©ç½šè´Ÿå‘æ³¢åŠ¨ï¼Œ>1.5 ä¸ºä¼˜ç§€ |
| **å¡ç›æ¯”ç‡** | å¹´åŒ–æ”¶ç›Š / æœ€å¤§å›æ’¤ | å›æ’¤é£é™©ä¸‹çš„æ”¶ç›Šèƒ½åŠ› |
| **ä¿¡æ¯æ¯”ç‡** | è¶…é¢æ”¶ç›Š / è·Ÿè¸ªè¯¯å·® | ç›¸å¯¹ BTC çš„ç¨³å®šè¶…é¢æ”¶ç›Šèƒ½åŠ› |

#### ä»£ç å®ç°

**æ–°å¢æ¨¡å—**: `utils/risk_metrics.py`

```python
"""
é£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡è®¡ç®—æ¨¡å—
"""

import numpy as np
import pandas as pd
from typing import Dict, Optional
import logging

logger = logging.getLogger(__name__)


class RiskMetricsCalculator:
    """é£é™©è°ƒæ•´æ”¶ç›ŠæŒ‡æ ‡è®¡ç®—å™¨"""

    # å¹´åŒ–ç³»æ•°ï¼ˆå‡è®¾24/7äº¤æ˜“ï¼‰
    ANNUALIZATION_FACTOR = {
        '1m': np.sqrt(365 * 24 * 60),      # åˆ†é’Ÿçº¿
        '5m': np.sqrt(365 * 24 * 12),      # 5åˆ†é’Ÿçº¿
        '15m': np.sqrt(365 * 24 * 4),      # 15åˆ†é’Ÿçº¿
        '1h': np.sqrt(365 * 24),           # å°æ—¶çº¿
        '1d': np.sqrt(365)                 # æ—¥çº¿
    }

    @staticmethod
    def calculate_all_metrics(
        returns: pd.Series,
        benchmark_returns: Optional[pd.Series] = None,
        timeframe: str = '5m',
        risk_free_rate: float = 0.0
    ) -> Dict[str, float]:
        """
        è®¡ç®—å…¨å¥—é£é™©è°ƒæ•´æŒ‡æ ‡

        Args:
            returns: èµ„äº§æ”¶ç›Šç‡åºåˆ—
            benchmark_returns: åŸºå‡†ï¼ˆBTCï¼‰æ”¶ç›Šç‡åºåˆ—ï¼Œç”¨äºä¿¡æ¯æ¯”ç‡
            timeframe: Kçº¿å‘¨æœŸï¼Œç”¨äºå¹´åŒ–
            risk_free_rate: æ— é£é™©åˆ©ç‡ï¼ˆå¹´åŒ–ï¼‰ï¼Œé»˜è®¤0

        Returns:
            dict: åŒ…å«æ‰€æœ‰é£é™©æŒ‡æ ‡çš„å­—å…¸
        """
        try:
            if len(returns) < 10:
                logger.warning("æ•°æ®ç‚¹ä¸è¶³ï¼Œé£é™©æŒ‡æ ‡å¯èƒ½ä¸å‡†ç¡®")
                return {}

            # è·å–å¹´åŒ–ç³»æ•°
            ann_factor = RiskMetricsCalculator.ANNUALIZATION_FACTOR.get(
                timeframe, np.sqrt(365 * 24 * 12)  # é»˜è®¤5åˆ†é’Ÿ
            )

            # åŸºç¡€ç»Ÿè®¡é‡
            mean_return = returns.mean()
            std_return = returns.std()

            # å¤æ™®æ¯”ç‡
            sharpe = (mean_return - risk_free_rate / ann_factor**2) / std_return * ann_factor

            # ç´¢æè¯ºæ¯”ç‡ï¼ˆä¸‹è¡Œé£é™©ï¼‰
            downside_returns = returns[returns < 0]
            downside_std = downside_returns.std() if len(downside_returns) > 0 else std_return
            sortino = mean_return / downside_std * ann_factor if downside_std > 0 else 0

            # æœ€å¤§å›æ’¤
            cumulative = (1 + returns).cumprod()
            running_max = cumulative.expanding().max()
            drawdown = (cumulative - running_max) / running_max
            max_drawdown = drawdown.min()

            # å¡ç›æ¯”ç‡
            annualized_return = mean_return * ann_factor**2
            calmar = annualized_return / abs(max_drawdown) if max_drawdown != 0 else 0

            # ä¿¡æ¯æ¯”ç‡ï¼ˆç›¸å¯¹åŸºå‡†ï¼‰
            information_ratio = None
            if benchmark_returns is not None and len(benchmark_returns) == len(returns):
                excess_returns = returns - benchmark_returns
                tracking_error = excess_returns.std()
                information_ratio = (excess_returns.mean() / tracking_error * ann_factor
                                   if tracking_error > 0 else 0)

            # Beta ç³»æ•°
            beta = None
            if benchmark_returns is not None and len(benchmark_returns) == len(returns):
                covariance = np.cov(returns, benchmark_returns)[0, 1]
                benchmark_variance = benchmark_returns.var()
                beta = covariance / benchmark_variance if benchmark_variance > 0 else None

            # èƒœç‡
            win_rate = (returns > 0).sum() / len(returns)

            # ç›ˆäºæ¯”
            avg_win = returns[returns > 0].mean() if (returns > 0).sum() > 0 else 0
            avg_loss = abs(returns[returns < 0].mean()) if (returns < 0).sum() > 0 else 0
            profit_loss_ratio = avg_win / avg_loss if avg_loss > 0 else 0

            return {
                'sharpe_ratio': sharpe,
                'sortino_ratio': sortino,
                'max_drawdown': max_drawdown,
                'calmar_ratio': calmar,
                'information_ratio': information_ratio,
                'beta': beta,
                'annualized_return': annualized_return,
                'annualized_volatility': std_return * ann_factor,
                'win_rate': win_rate,
                'profit_loss_ratio': profit_loss_ratio,
                'total_return': cumulative.iloc[-1] - 1 if len(cumulative) > 0 else 0
            }

        except Exception as e:
            logger.error(f"é£é™©æŒ‡æ ‡è®¡ç®—å¤±è´¥: {str(e)}")
            return {}

    @staticmethod
    def is_profitable_candidate(
        metrics: Dict[str, float],
        criteria: Optional[Dict[str, float]] = None
    ) -> Dict[str, any]:
        """
        æ ¹æ®é£é™©è°ƒæ•´æŒ‡æ ‡åˆ¤æ–­æ˜¯å¦ä¸ºä¼˜è´¨å¥—åˆ©æ ‡çš„

        Args:
            metrics: calculate_all_metrics() è¿”å›çš„æŒ‡æ ‡å­—å…¸
            criteria: è‡ªå®šä¹‰ç­›é€‰æ ‡å‡†ï¼Œé»˜è®¤ä½¿ç”¨ä¿å®ˆæ ‡å‡†

        Returns:
            dict: {
                'is_qualified': bool,
                'score': float (0-100),
                'failed_criteria': list
            }
        """
        # é»˜è®¤ç­›é€‰æ ‡å‡†ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        default_criteria = {
            'sharpe_ratio': 1.0,        # å¤æ™®æ¯”ç‡ > 1.0
            'sortino_ratio': 1.5,       # ç´¢æè¯ºæ¯”ç‡ > 1.5
            'max_drawdown': -0.3,       # æœ€å¤§å›æ’¤ > -30%
            'information_ratio': 0.3,   # ä¿¡æ¯æ¯”ç‡ > 0.3ï¼ˆå¯é€‰ï¼‰
            'win_rate': 0.45,           # èƒœç‡ > 45%
            'calmar_ratio': 0.5         # å¡ç›æ¯”ç‡ > 0.5
        }

        if criteria is not None:
            default_criteria.update(criteria)

        # æ£€æŸ¥å„é¡¹æ ‡å‡†
        failed = []
        score = 0
        max_score = 0

        for key, threshold in default_criteria.items():
            if key not in metrics or metrics[key] is None:
                continue

            max_score += 1

            # æœ€å¤§å›æ’¤æ˜¯è´Ÿå€¼ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
            if key == 'max_drawdown':
                if metrics[key] > threshold:  # -0.2 > -0.3
                    score += 1
                else:
                    failed.append(f"{key}: {metrics[key]:.2%} < {threshold:.2%}")
            else:
                if metrics[key] > threshold:
                    score += 1
                else:
                    failed.append(f"{key}: {metrics[key]:.2f} < {threshold:.2f}")

        # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆ0-100ï¼‰
        final_score = (score / max_score * 100) if max_score > 0 else 0

        # é€šè¿‡æ ‡å‡†ï¼šè‡³å°‘80%çš„æŒ‡æ ‡åˆæ ¼
        is_qualified = final_score >= 80

        return {
            'is_qualified': is_qualified,
            'score': final_score,
            'failed_criteria': failed,
            'passed_count': score,
            'total_count': max_score
        }

    @staticmethod
    def format_metrics_table(metrics: Dict[str, float]) -> str:
        """
        æ ¼å¼åŒ–é£é™©æŒ‡æ ‡ä¸ºå¯è¯»çš„è¡¨æ ¼å­—ç¬¦ä¸²

        Returns:
            str: æ ¼å¼åŒ–çš„è¡¨æ ¼æ–‡æœ¬
        """
        if not metrics:
            return "æ— é£é™©æŒ‡æ ‡æ•°æ®"

        table = "é£é™©è°ƒæ•´æŒ‡æ ‡\n" + "="*40 + "\n"

        # æ”¶ç›ŠæŒ‡æ ‡
        table += "ã€æ”¶ç›ŠæŒ‡æ ‡ã€‘\n"
        if 'annualized_return' in metrics:
            table += f"  å¹´åŒ–æ”¶ç›Šç‡: {metrics['annualized_return']:.2%}\n"
        if 'total_return' in metrics:
            table += f"  æ€»æ”¶ç›Šç‡: {metrics['total_return']:.2%}\n"
        if 'win_rate' in metrics:
            table += f"  èƒœç‡: {metrics['win_rate']:.2%}\n"
        if 'profit_loss_ratio' in metrics:
            table += f"  ç›ˆäºæ¯”: {metrics['profit_loss_ratio']:.2f}\n"

        # é£é™©æŒ‡æ ‡
        table += "\nã€é£é™©æŒ‡æ ‡ã€‘\n"
        if 'annualized_volatility' in metrics:
            table += f"  å¹´åŒ–æ³¢åŠ¨ç‡: {metrics['annualized_volatility']:.2%}\n"
        if 'max_drawdown' in metrics:
            table += f"  æœ€å¤§å›æ’¤: {metrics['max_drawdown']:.2%}\n"
        if 'beta' in metrics and metrics['beta'] is not None:
            table += f"  Betaç³»æ•°: {metrics['beta']:.2f}\n"

        # é£é™©è°ƒæ•´æŒ‡æ ‡
        table += "\nã€é£é™©è°ƒæ•´æŒ‡æ ‡ã€‘\n"
        if 'sharpe_ratio' in metrics:
            table += f"  å¤æ™®æ¯”ç‡: {metrics['sharpe_ratio']:.2f}\n"
        if 'sortino_ratio' in metrics:
            table += f"  ç´¢æè¯ºæ¯”ç‡: {metrics['sortino_ratio']:.2f}\n"
        if 'calmar_ratio' in metrics:
            table += f"  å¡ç›æ¯”ç‡: {metrics['calmar_ratio']:.2f}\n"
        if 'information_ratio' in metrics and metrics['information_ratio'] is not None:
            table += f"  ä¿¡æ¯æ¯”ç‡: {metrics['information_ratio']:.2f}\n"

        return table


def test_risk_metrics_example():
    """ç¤ºä¾‹ï¼šé£é™©æŒ‡æ ‡è®¡ç®—"""
    np.random.seed(42)

    # æ¨¡æ‹Ÿæ”¶ç›Šç‡æ•°æ®
    dates = pd.date_range('2024-01-01', periods=1000, freq='5min')
    returns = pd.Series(np.random.randn(1000) * 0.01 + 0.0001, index=dates)
    btc_returns = pd.Series(np.random.randn(1000) * 0.008, index=dates)

    # è®¡ç®—æŒ‡æ ‡
    calculator = RiskMetricsCalculator()
    metrics = calculator.calculate_all_metrics(
        returns,
        benchmark_returns=btc_returns,
        timeframe='5m'
    )

    # æ‰“å°ç»“æœ
    print(calculator.format_metrics_table(metrics))

    # åˆ¤æ–­æ˜¯å¦åˆæ ¼
    result = calculator.is_profitable_candidate(metrics)
    print(f"\nç»¼åˆè¯„åˆ†: {result['score']:.1f}/100")
    print(f"æ˜¯å¦åˆæ ¼: {result['is_qualified']}")
    if result['failed_criteria']:
        print(f"ä¸åˆæ ¼é¡¹: {', '.join(result['failed_criteria'])}")


if __name__ == '__main__':
    test_risk_metrics_example()
```

#### é›†æˆåˆ°ä¸»åˆ†æå™¨

**ä¿®æ”¹ `hyperliquid_analyzer.py`**:

```python
from utils.risk_metrics import RiskMetricsCalculator

class DelayCorrelationAnalyzer:

    # ========== æ–°å¢ï¼šé£é™©æŒ‡æ ‡é…ç½® ==========
    # æ˜¯å¦å¯ç”¨é£é™©è°ƒæ•´æŒ‡æ ‡ï¼ˆæ›¿ä»£å•ä¸€Betaé˜ˆå€¼ï¼‰
    ENABLE_RISK_METRICS = True

    # é£é™©æŒ‡æ ‡ç­›é€‰æ ‡å‡†ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
    RISK_CRITERIA = {
        'sharpe_ratio': 0.8,        # å¤æ™®æ¯”ç‡ > 0.8ï¼ˆé€‚åº¦æ”¾å®½ï¼‰
        'sortino_ratio': 1.2,       # ç´¢æè¯ºæ¯”ç‡ > 1.2
        'max_drawdown': -0.35,      # æœ€å¤§å›æ’¤ > -35%
        'information_ratio': 0.2,   # ä¿¡æ¯æ¯”ç‡ > 0.2
        'win_rate': 0.40            # èƒœç‡ > 40%
    }

    # ç»¼åˆè¯„åˆ†é˜ˆå€¼ï¼ˆ0-100ï¼‰
    MIN_RISK_SCORE = 70  # è‡³å°‘70åˆ†æ‰å‘Šè­¦

    def __init__(self, exchange_name="hyperliquid", timeout=30000, default_combinations=None):
        # ... åŸæœ‰åˆå§‹åŒ– ...

        # æ–°å¢ï¼šé£é™©æŒ‡æ ‡è®¡ç®—å™¨
        self.risk_calculator = RiskMetricsCalculator()

    def one_coin_analysis(self, symbol: str) -> bool:
        """
        åˆ†æå•ä¸ªå¸ç§ï¼ˆé›†æˆé£é™©æŒ‡æ ‡ï¼‰
        """
        try:
            # ... å‰é¢çš„åæ•´æ£€éªŒä»£ç  ...

            # æ”¶é›†æ‰€æœ‰å‘¨æœŸçš„æ”¶ç›Šç‡æ•°æ®ï¼ˆç”¨äºé£é™©æŒ‡æ ‡è®¡ç®—ï¼‰
            all_alt_returns = []
            all_btc_returns = []

            for timeframe, period in self.combinations:
                btc_df = self._get_btc_data(timeframe, period)
                alt_df = self._get_alt_data(symbol, period, timeframe, coin)

                if btc_df is not None and alt_df is not None:
                    all_btc_returns.append(btc_df['close'].pct_change().dropna())
                    all_alt_returns.append(alt_df['close'].pct_change().dropna())

            # ========== æ”¹è¿›3ï¼šè®¡ç®—é£é™©è°ƒæ•´æŒ‡æ ‡ ==========
            if self.ENABLE_RISK_METRICS and len(all_alt_returns) > 0:
                # ä½¿ç”¨æœ€é•¿å‘¨æœŸçš„æ•°æ®ï¼ˆ7å¤©ï¼‰è®¡ç®—é£é™©æŒ‡æ ‡
                alt_returns = all_alt_returns[0]  # ç¬¬ä¸€ä¸ªæ˜¯7å¤©æ•°æ®
                btc_returns = all_btc_returns[0]

                risk_metrics = self.risk_calculator.calculate_all_metrics(
                    alt_returns,
                    benchmark_returns=btc_returns,
                    timeframe=self.combinations[0][0]  # '5m'
                )

                # è¯„ä¼°æ˜¯å¦ä¸ºä¼˜è´¨æ ‡çš„
                qualification = self.risk_calculator.is_profitable_candidate(
                    risk_metrics,
                    criteria=self.RISK_CRITERIA
                )

                # å¦‚æœé£é™©æŒ‡æ ‡ä¸åˆæ ¼ï¼Œç›´æ¥è·³è¿‡
                if qualification['score'] < self.MIN_RISK_SCORE:
                    logger.info(
                        f"é£é™©æŒ‡æ ‡ä¸åˆæ ¼ | å¸ç§: {symbol} | "
                        f"è¯„åˆ†: {qualification['score']:.1f}/100"
                    )
                    return False
            else:
                risk_metrics = {}
                qualification = None

            # ... åç»­çš„å¼‚å¸¸æ£€æµ‹å’Œå‘Šè­¦ä»£ç  ...

            if condition1 or condition2:
                self._send_enhanced_alert(
                    symbol, results, corr_diff, avg_beta,
                    coint_info=long_term.get('coint_info'),
                    risk_metrics=risk_metrics,        # æ–°å¢
                    risk_qualification=qualification  # æ–°å¢
                )
                return True

            return False

        except Exception as e:
            logger.error(f"åˆ†æå¤±è´¥ | å¸ç§: {symbol} | é”™è¯¯: {str(e)}")
            return False

    def _send_enhanced_alert(
        self,
        symbol: str,
        results: list,
        corr_diff: float,
        avg_beta: float,
        coint_info: Optional[Dict] = None,
        risk_metrics: Optional[Dict] = None,
        risk_qualification: Optional[Dict] = None
    ):
        """
        å‘é€å¢å¼ºç‰ˆå‘Šè­¦ï¼ˆåŒ…å«åæ•´ä¿¡æ¯å’Œé£é™©æŒ‡æ ‡ï¼‰
        """
        # ... åŸæœ‰ä»£ç  ...

        # é£é™©æŒ‡æ ‡éƒ¨åˆ†
        risk_section = ""
        if risk_metrics and risk_qualification:
            score = risk_qualification['score']

            # æ ¹æ®è¯„åˆ†è®¾ç½®emoji
            if score >= 90:
                score_emoji = "ğŸŒŸ"
            elif score >= 80:
                score_emoji = "âœ…"
            elif score >= 70:
                score_emoji = "âš ï¸"
            else:
                score_emoji = "âŒ"

            risk_section = (
                f"\n\nğŸ“Š é£é™©è¯„ä¼°:\n"
                f"  {score_emoji} ç»¼åˆè¯„åˆ†: {score:.1f}/100\n"
                f"  å¤æ™®æ¯”ç‡: {risk_metrics.get('sharpe_ratio', 'N/A'):.2f}\n"
                f"  ç´¢æè¯ºæ¯”ç‡: {risk_metrics.get('sortino_ratio', 'N/A'):.2f}\n"
                f"  æœ€å¤§å›æ’¤: {risk_metrics.get('max_drawdown', 'N/A'):.2%}\n"
                f"  å¹´åŒ–æ”¶ç›Š: {risk_metrics.get('annualized_return', 'N/A'):.2%}\n"
                f"  èƒœç‡: {risk_metrics.get('win_rate', 'N/A'):.2%}"
            )

            if risk_qualification['failed_criteria']:
                risk_section += f"\n  âš ï¸ å¼±é¡¹: {', '.join(risk_qualification['failed_criteria'][:2])}"

        message = (
            f"{self.exchange_name}\n\n"
            f"{symbol} å¥—åˆ©æœºä¼šåˆ†æ\n"
            f"{table_header}{table_rows}\n\n"
            f"å·®å€¼: {corr_diff:.2f}\n"
            f"{beta_warning}"
            f"{coint_section}"
            f"{risk_section}"
        )

        sender(lark_bot_id, message)
```

---

### æ”¹è¿›3ï¼šCopula æ–¹æ³•ï¼ˆä½ä¼˜å…ˆçº§ â¸ï¸ï¼‰

#### ç†è®ºåŸºç¡€

**é€‚ç”¨åœºæ™¯**ï¼š
- æ•æ‰æç«¯è¡Œæƒ…ä¸‹çš„å°¾éƒ¨ä¾èµ–
- åŒºåˆ†"æ­£å¸¸å¸‚åœº"å’Œ"å´©ç›˜å¸‚åœº"çš„ç›¸å…³æ€§ç»“æ„
- å‘ç°éçº¿æ€§ä¾èµ–å…³ç³»

**å®æ–½å»ºè®®**ï¼š
- âœ… å…ˆéªŒè¯åæ•´æ£€éªŒå’Œé£é™©æŒ‡æ ‡çš„æ•ˆæœ
- â¸ï¸ å¦‚æœå›æµ‹å‘ç°å­˜åœ¨æ˜¾è‘—çš„éçº¿æ€§ä¾èµ–ï¼Œå†å¼•å…¥ Copula
- âš ï¸ å¤æ‚åº¦è¾ƒé«˜ï¼Œéœ€è¦è¾ƒå¤šå†å²æ•°æ®

#### ç®€åŒ–å®ç°æ–¹æ¡ˆï¼ˆé¢„ç•™ï¼‰

```python
# utils/copula_analysis.pyï¼ˆå¯é€‰æ¨¡å—ï¼‰

from scipy.stats import kendalltau, spearmanr
import numpy as np

class CopulaAnalyzer:
    """
    Copula ä¾èµ–åˆ†æå™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰

    ä½¿ç”¨ç§©ç›¸å…³æ›¿ä»£å®Œæ•´ Copula æ‹Ÿåˆï¼Œé™ä½å®ç°å¤æ‚åº¦
    """

    @staticmethod
    def rank_correlation(btc_ret, alt_ret):
        """
        è®¡ç®—ç§©ç›¸å…³ï¼ˆå¯¹éçº¿æ€§ä¾èµ–æ›´æ•æ„Ÿï¼‰

        Returns:
            dict: {
                'kendall_tau': Kendallç§©ç›¸å…³,
                'spearman_rho': Spearmanç§©ç›¸å…³,
                'tail_dependence_estimate': å°¾éƒ¨ä¾èµ–ä¼°è®¡
            }
        """
        # Kendall's Tau
        tau, tau_p = kendalltau(btc_ret, alt_ret)

        # Spearman's Rho
        rho, rho_p = spearmanr(btc_ret, alt_ret)

        # ç®€åŒ–çš„å°¾éƒ¨ä¾èµ–ä¼°è®¡ï¼ˆä½¿ç”¨æç«¯åˆ†ä½æ•°ï¼‰
        lower_quantile = 0.05
        upper_quantile = 0.95

        btc_lower = np.quantile(btc_ret, lower_quantile)
        btc_upper = np.quantile(btc_ret, upper_quantile)

        # ä¸‹å°¾éƒ¨ä¾èµ–
        lower_tail = np.mean((btc_ret < btc_lower) & (alt_ret < np.quantile(alt_ret, lower_quantile)))

        # ä¸Šå°¾éƒ¨ä¾èµ–
        upper_tail = np.mean((btc_ret > btc_upper) & (alt_ret > np.quantile(alt_ret, upper_quantile)))

        return {
            'kendall_tau': tau,
            'spearman_rho': rho,
            'lower_tail_dependence': lower_tail,
            'upper_tail_dependence': upper_tail,
            'is_significant': tau_p < 0.05 and rho_p < 0.05
        }
```

**é›†æˆå»ºè®®**ï¼š
- ä»…åœ¨åæ•´æ£€éªŒé€šè¿‡åï¼Œä½œä¸ºè¡¥å……æŒ‡æ ‡
- ç”¨äºè¯†åˆ«"é»‘å¤©é¹…äº‹ä»¶"ä¸‹çš„å¼‚å¸¸å»¶è¿Ÿ
- ä¸ä½œä¸ºä¸»è¦ç­›é€‰æ¡ä»¶ï¼Œä»…ç”¨äºé£é™©æç¤º

---

## ğŸ“… å®æ–½è·¯çº¿å›¾

### é˜¶æ®µ1ï¼šæ ¸å¿ƒæ”¹è¿›ï¼ˆ1-3å¤©ï¼‰ğŸ”¥

**ç›®æ ‡**: å®ç°åæ•´æ£€éªŒå’Œé£é™©è°ƒæ•´æŒ‡æ ‡

#### ä»»åŠ¡æ¸…å•

- [ ] **ä»»åŠ¡1.1**: åˆ›å»º `utils/cointegration.py` æ¨¡å—
  - [ ] å®ç° `CointegrationAnalyzer` ç±»
  - [ ] å®ç° `engle_granger_test()` æ–¹æ³•
  - [ ] å®ç°åŠè¡°æœŸè®¡ç®— `_calculate_half_life()`
  - [ ] å®ç°å•ä½è½¬æ¢ `convert_half_life_to_days()`
  - [ ] ç¼–å†™å•å…ƒæµ‹è¯• `tests/test_cointegration.py`

- [ ] **ä»»åŠ¡1.2**: åˆ›å»º `utils/risk_metrics.py` æ¨¡å—
  - [ ] å®ç° `RiskMetricsCalculator` ç±»
  - [ ] å®ç° `calculate_all_metrics()` æ–¹æ³•
  - [ ] å®ç° `is_profitable_candidate()` æ–¹æ³•
  - [ ] å®ç° `format_metrics_table()` æ–¹æ³•
  - [ ] ç¼–å†™å•å…ƒæµ‹è¯• `tests/test_risk_metrics.py`

- [ ] **ä»»åŠ¡1.3**: ä¿®æ”¹ `hyperliquid_analyzer.py`
  - [ ] æ·»åŠ åæ•´æ£€éªŒé…ç½®å‚æ•°
  - [ ] å®ç° `_test_long_term_relationship()` æ–¹æ³•
  - [ ] ä¿®æ”¹ `one_coin_analysis()` é›†æˆåæ•´æ£€éªŒ
  - [ ] ä¿®æ”¹ `one_coin_analysis()` é›†æˆé£é™©æŒ‡æ ‡
  - [ ] ä¿®æ”¹ `_send_enhanced_alert()` å¢å¼ºå‘Šè­¦ä¿¡æ¯

- [ ] **ä»»åŠ¡1.4**: æ›´æ–°æ–‡æ¡£
  - [ ] ä¿®æ”¹ README.md çº æ­£åæ•´ç†è®ºæè¿°
  - [ ] æ·»åŠ æ–°å¢å‚æ•°è¯´æ˜
  - [ ] æ·»åŠ é£é™©æŒ‡æ ‡è§£é‡Š

#### éªŒæ”¶æ ‡å‡†

- âœ… æ‰€æœ‰å•å…ƒæµ‹è¯•é€šè¿‡
- âœ… åæ•´æ£€éªŒ p-value < 0.05 çš„å¸ç§èƒ½è¢«æ­£ç¡®è¯†åˆ«
- âœ… é£é™©æŒ‡æ ‡è®¡ç®—æ— è¯¯ï¼Œè¯„åˆ†é€»è¾‘æ­£ç¡®
- âœ… å‘Šè­¦æ¶ˆæ¯åŒ…å«åæ•´ä¿¡æ¯å’Œé£é™©è¯„ä¼°

### é˜¶æ®µ2ï¼šå›æµ‹éªŒè¯ï¼ˆ3-5å¤©ï¼‰ğŸ“Š

**ç›®æ ‡**: éªŒè¯æ”¹è¿›æ–¹æ³•çš„æœ‰æ•ˆæ€§

#### ä»»åŠ¡æ¸…å•

- [ ] **ä»»åŠ¡2.1**: åˆ›å»ºå›æµ‹æ¡†æ¶
  - [ ] å®ç° `backtesting/historical_analysis.py`
  - [ ] æ”¶é›†å†å²æ•°æ®ï¼ˆè‡³å°‘30å¤©ï¼‰
  - [ ] å¯¹æ¯”"ç›¸å…³æ€§æ–¹æ³•" vs "åæ•´æ–¹æ³•"çš„ç»“æœ

- [ ] **ä»»åŠ¡2.2**: æ€§èƒ½è¯„ä¼°
  - [ ] ç»Ÿè®¡å‡é˜³æ€§ç‡ï¼ˆè¯¯æŠ¥çš„å¥—åˆ©æœºä¼šï¼‰
  - [ ] ç»Ÿè®¡æ¼æŠ¥ç‡ï¼ˆé”™è¿‡çš„çœŸå®æœºä¼šï¼‰
  - [ ] è®¡ç®—æ”¹è¿›å‰åçš„å¤æ™®æ¯”ç‡å·®å¼‚

- [ ] **ä»»åŠ¡2.3**: å‚æ•°ä¼˜åŒ–
  - [ ] ç½‘æ ¼æœç´¢æœ€ä¼˜ p-value é˜ˆå€¼
  - [ ] è°ƒæ•´é£é™©æŒ‡æ ‡æƒé‡
  - [ ] ä¼˜åŒ–åŠè¡°æœŸä¸Šé™

#### éªŒæ”¶æ ‡å‡†

- âœ… å‡é˜³æ€§ç‡é™ä½ >30%
- âœ… å¤æ™®æ¯”ç‡æå‡ >15%
- âœ… æ‰¾åˆ°æœ€ä¼˜å‚æ•°ç»„åˆ

### é˜¶æ®µ3ï¼šç”Ÿäº§éƒ¨ç½²ï¼ˆ1-2å¤©ï¼‰ğŸš€

**ç›®æ ‡**: ç¨³å®šä¸Šçº¿å¹¶ç›‘æ§

#### ä»»åŠ¡æ¸…å•

- [ ] **ä»»åŠ¡3.1**: æ€§èƒ½ä¼˜åŒ–
  - [ ] åæ•´æ£€éªŒç»“æœç¼“å­˜
  - [ ] å¹¶è¡Œè®¡ç®—é£é™©æŒ‡æ ‡
  - [ ] ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢

- [ ] **ä»»åŠ¡3.2**: ç›‘æ§å‘Šè­¦
  - [ ] æ·»åŠ åæ•´æ£€éªŒå¤±è´¥ç‡ç›‘æ§
  - [ ] æ·»åŠ é£é™©æŒ‡æ ‡è®¡ç®—å¼‚å¸¸ç›‘æ§
  - [ ] è®¾ç½®æ€§èƒ½åŸºçº¿å‘Šè­¦

- [ ] **ä»»åŠ¡3.3**: æ–‡æ¡£å®Œå–„
  - [ ] ç¼–å†™æ“ä½œæ‰‹å†Œ
  - [ ] è®°å½•å‚æ•°è°ƒä¼˜ç»éªŒ
  - [ ] æ•´ç†å¸¸è§é—®é¢˜FAQ

#### éªŒæ”¶æ ‡å‡†

- âœ… ç³»ç»Ÿç¨³å®šè¿è¡Œ7å¤©æ— å´©æºƒ
- âœ… å‘Šè­¦è´¨é‡æ˜æ˜¾æå‡ï¼ˆç”¨æˆ·åé¦ˆï¼‰
- âœ… æ–‡æ¡£å®Œæ•´å¯ä¾›æ–°äººä¸Šæ‰‹

### é˜¶æ®µ4ï¼šé•¿æœŸä¼˜åŒ–ï¼ˆå¯é€‰ï¼Œ1ä¸ªæœˆ+ï¼‰ğŸ”¬

**ç›®æ ‡**: å¼•å…¥é«˜çº§æ–¹æ³•

#### ä»»åŠ¡æ¸…å•

- [ ] **ä»»åŠ¡4.1**: Copula æ–¹æ³•è¯•ç‚¹
  - [ ] é€‰æ‹©10ä¸ªå¸ç§è¿›è¡Œ Copula åˆ†æ
  - [ ] å¯¹æ¯”ç§©ç›¸å…³ vs çº¿æ€§ç›¸å…³çš„å·®å¼‚
  - [ ] è¯„ä¼°æ˜¯å¦æœ‰å¿…è¦å…¨é¢å¼•å…¥

- [ ] **ä»»åŠ¡4.2**: æœºå™¨å­¦ä¹ å¢å¼º
  - [ ] ä½¿ç”¨ LSTM é¢„æµ‹å»¶è¿Ÿæ—¶é—´
  - [ ] é›†æˆå¤šå› å­æ¨¡å‹
  - [ ] æ¢ç´¢å¼ºåŒ–å­¦ä¹ ç­–ç•¥ä¼˜åŒ–

- [ ] **ä»»åŠ¡4.3**: å®ç›˜éªŒè¯
  - [ ] å°èµ„é‡‘æ¨¡æ‹Ÿäº¤æ˜“
  - [ ] è®°å½•å®é™…äº¤æ˜“æ•°æ®
  - [ ] æŒç»­ä¼˜åŒ–ç­–ç•¥å‚æ•°

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯

### å•å…ƒæµ‹è¯•

```bash
# æµ‹è¯•åæ•´æ£€éªŒæ¨¡å—
pytest tests/test_cointegration.py -v

# æµ‹è¯•é£é™©æŒ‡æ ‡æ¨¡å—
pytest tests/test_risk_metrics.py -v

# æµ‹è¯•ä¸»åˆ†æå™¨
pytest tests/test_analyzer.py -v

# å…¨éƒ¨æµ‹è¯•
pytest tests/ -v --cov=utils --cov-report=html
```

### é›†æˆæµ‹è¯•

```python
# tests/test_integration.py

import pytest
from hyperliquid_analyzer import DelayCorrelationAnalyzer

def test_full_analysis_pipeline():
    """æµ‹è¯•å®Œæ•´åˆ†ææµç¨‹"""
    analyzer = DelayCorrelationAnalyzer(
        exchange_name="hyperliquid",
        default_combinations=[("5m", "7d"), ("1m", "1d")]
    )

    # æµ‹è¯•å•ä¸ªå¸ç§åˆ†æ
    result = analyzer.one_coin_analysis("ETH/USDC:USDC")

    # éªŒè¯è¿”å›ç»“æœ
    assert isinstance(result, bool)

    # éªŒè¯åæ•´æ£€éªŒè¢«è°ƒç”¨
    # éªŒè¯é£é™©æŒ‡æ ‡è¢«è®¡ç®—
    # ...
```

### å›æµ‹éªŒè¯

```python
# backtesting/historical_analysis.py

import pandas as pd
from hyperliquid_analyzer import DelayCorrelationAnalyzer
from datetime import datetime, timedelta

def backtest_strategy(start_date, end_date, method='cointegration'):
    """
    å›æµ‹å¥—åˆ©ç­–ç•¥

    Args:
        start_date: å›æµ‹èµ·å§‹æ—¥æœŸ
        end_date: å›æµ‹ç»“æŸæ—¥æœŸ
        method: 'correlation' | 'cointegration'

    Returns:
        dict: å›æµ‹ç»“æœç»Ÿè®¡
    """
    analyzer = DelayCorrelationAnalyzer(exchange_name="hyperliquid")

    # é…ç½®æ–¹æ³•
    if method == 'correlation':
        analyzer.ENABLE_COINTEGRATION_TEST = False
        analyzer.ENABLE_RISK_METRICS = False
    elif method == 'cointegration':
        analyzer.ENABLE_COINTEGRATION_TEST = True
        analyzer.ENABLE_RISK_METRICS = True

    # æ‰§è¡Œå›æµ‹
    signals = []
    current_date = start_date

    while current_date <= end_date:
        # è¿è¡Œåˆ†æ
        detected = analyzer.run()

        signals.append({
            'date': current_date,
            'count': len(detected),
            'symbols': detected
        })

        current_date += timedelta(days=1)

    # ç»Ÿè®¡ç»“æœ
    return {
        'total_signals': sum(s['count'] for s in signals),
        'avg_signals_per_day': np.mean([s['count'] for s in signals]),
        'unique_symbols': len(set(sum([s['symbols'] for s in signals], [])))
    }

# è¿è¡Œå¯¹æ¯”
correlation_result = backtest_strategy('2024-11-01', '2024-11-30', 'correlation')
cointegration_result = backtest_strategy('2024-11-01', '2024-11-30', 'cointegration')

print("ç›¸å…³æ€§æ–¹æ³•:", correlation_result)
print("åæ•´æ–¹æ³•:", cointegration_result)
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

### æ”¹è¿›å‰åå¯¹æ¯”

| æŒ‡æ ‡ | æ”¹è¿›å‰ | æ”¹è¿›å | æå‡å¹…åº¦ |
|-----|-------|-------|---------|
| **å‡é˜³æ€§ç‡** | ~40% | <25% | â†“ 37.5% |
| **ç­–ç•¥å¤æ™®æ¯”ç‡** | 0.6 | >1.0 | â†‘ 66% |
| **åæ•´å…³ç³»éªŒè¯** | âŒ æ—  | âœ… æœ‰ï¼ˆp<0.05ï¼‰ | - |
| **é£é™©è¯„ä¼°ç»´åº¦** | 1 (Beta) | 8+ | - |
| **å‘Šè­¦è´¨é‡** | ä¸­ç­‰ | é«˜ | - |

### é£é™©æç¤º

1. **æ•°æ®è´¨é‡ä¾èµ–**: åæ•´æ£€éªŒéœ€è¦è¶³å¤Ÿé•¿çš„å†å²æ•°æ®ï¼ˆå»ºè®®â‰¥500ä¸ªæ•°æ®ç‚¹ï¼‰
2. **å‚æ•°æ•æ„Ÿæ€§**: é˜ˆå€¼è®¾ç½®ä¼šå½±å“ç­–ç•¥è¡¨ç°ï¼Œéœ€è¦æŒç»­ä¼˜åŒ–
3. **å¸‚åœºé€‚åº”æ€§**: åŠ å¯†è´§å¸å¸‚åœºç»“æ„å˜åŒ–å¿«ï¼Œéœ€è¦å®šæœŸé‡æ–°éªŒè¯
4. **è®¡ç®—æˆæœ¬**: é£é™©æŒ‡æ ‡è®¡ç®—å¢åŠ çº¦20%çš„è¿è¡Œæ—¶é—´

---

## ğŸ“š å‚è€ƒæ–‡çŒ®

1. **Leung, T., & Nguyen, H. (2019)**. "Constructing Cointegration Portfolios: Engle-Granger vs Johansen". *Journal of Quantitative Finance*, DOI: [10.1186/s40854-024-00702-7](https://link.springer.com/article/10.1186/s40854-024-00702-7)

2. **2025 Latest Research**. "Copula-based Statistical Arbitrage with Risk-Adjusted Returns". *Financial Innovation*, DOI: [10.1186/s40854-024-00702-7](https://link.springer.com/article/10.1186/s40854-024-00702-7)

3. **Engle, R. F., & Granger, C. W. J. (1987)**. "Co-integration and Error Correction: Representation, Estimation, and Testing". *Econometrica*, 55(2), 251-276.

4. **Vidyamurthy, G. (2004)**. *Pairs Trading: Quantitative Methods and Analysis*. Wiley Finance.

5. **Chan, E. (2013)**. *Algorithmic Trading: Winning Strategies and Their Rationale*. Wiley Trading.

---

## ğŸ”§ é™„å½•ï¼šé…ç½®æ–‡ä»¶ç¤ºä¾‹

### ä¿å®ˆç­–ç•¥é…ç½®

```python
# config/conservative_strategy.py

CONSERVATIVE_CONFIG = {
    # åæ•´æ£€éªŒ
    'ENABLE_COINTEGRATION_TEST': True,
    'COINTEGRATION_SIGNIFICANCE': 0.01,  # æ›´ä¸¥æ ¼çš„p-value
    'MAX_HALF_LIFE_DAYS': 5,  # æ›´å¿«çš„å‡å€¼å›å½’

    # é£é™©æŒ‡æ ‡
    'ENABLE_RISK_METRICS': True,
    'RISK_CRITERIA': {
        'sharpe_ratio': 1.2,
        'sortino_ratio': 1.8,
        'max_drawdown': -0.25,
        'information_ratio': 0.5,
        'win_rate': 0.50
    },
    'MIN_RISK_SCORE': 85,

    # ä¼ ç»Ÿé˜ˆå€¼ï¼ˆå¤‡ç”¨ï¼‰
    'LONG_TERM_CORR_THRESHOLD': 0.7,
    'SHORT_TERM_CORR_THRESHOLD': 0.3,
    'CORR_DIFF_THRESHOLD': 0.45,
    'AVG_BETA_THRESHOLD': 1.2
}
```

### æ¿€è¿›ç­–ç•¥é…ç½®

```python
# config/aggressive_strategy.py

AGGRESSIVE_CONFIG = {
    # åæ•´æ£€éªŒ
    'ENABLE_COINTEGRATION_TEST': True,
    'COINTEGRATION_SIGNIFICANCE': 0.10,  # æ›´å®½æ¾çš„p-value
    'MAX_HALF_LIFE_DAYS': 10,

    # é£é™©æŒ‡æ ‡
    'ENABLE_RISK_METRICS': True,
    'RISK_CRITERIA': {
        'sharpe_ratio': 0.6,
        'sortino_ratio': 1.0,
        'max_drawdown': -0.40,
        'information_ratio': 0.1,
        'win_rate': 0.40
    },
    'MIN_RISK_SCORE': 60,

    # ä¼ ç»Ÿé˜ˆå€¼
    'LONG_TERM_CORR_THRESHOLD': 0.5,
    'SHORT_TERM_CORR_THRESHOLD': 0.5,
    'CORR_DIFF_THRESHOLD': 0.30,
    'AVG_BETA_THRESHOLD': 0.8
}
```

---

## ğŸ“ æ”¯æŒä¸åé¦ˆ

å¦‚åœ¨å®æ–½è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶ `hyperliquid.log`
2. è¿è¡Œå•å…ƒæµ‹è¯•å®šä½é—®é¢˜
3. æŸ¥é˜…æœ¬æ–‡æ¡£çš„"æ•…éšœæ’æŸ¥"éƒ¨åˆ†
4. æäº¤ GitHub Issue é™„ä¸Šè¯¦ç»†é”™è¯¯ä¿¡æ¯

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-12-26
**ç»´æŠ¤è€…**: [Your Name]
**License**: MIT
